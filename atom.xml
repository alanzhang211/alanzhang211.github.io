<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>悟</title>
  
  <subtitle>心与心的交互</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://alanzhang.me/"/>
  <updated>2020-01-01T12:41:00.875Z</updated>
  <id>http://alanzhang.me/</id>
  
  <author>
    <name>Alan Zhang</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>理理自己的2019</title>
    <link href="http://alanzhang.me/2020/01/01/%E7%90%86%E7%90%86%E8%87%AA%E5%B7%B1%E7%9A%842019/"/>
    <id>http://alanzhang.me/2020/01/01/理理自己的2019/</id>
    <published>2020-01-01T10:52:37.000Z</published>
    <updated>2020-01-01T12:41:00.875Z</updated>
    
    <content type="html"><![CDATA[<p>今年的总结从何说起？元旦一天假期，本来想不写了。想想还是将这个习惯传承下去的好。不做深层次的分析，只是个流水总结。</p><h3 id="19总结"><a href="#19总结" class="headerlink" title="19总结"></a>19总结</h3><p>按照惯例，总结之前先看看上一年给自己“提纲”-<a href="http://alanzhang.me/2019/01/01/2018%E3%81%AE%E8%87%AA%E5%B7%B1/#more">2018の自己</a>中末尾提到。</p><a id="more"></a><h4 id="打分"><a href="#打分" class="headerlink" title="打分"></a>打分</h4><ul><li>公众号（70分）：基本平均下来一月一篇吧。包括生活，工作，学习总结等。如果您感兴趣，可扫码关注文末公众号，期待您的莅临。不过，专栏一项并没能完成，想写专栏确实需要更多的深度探索，继续努力。</li><li>读书笔记输出（60分）：读书笔记而言，可以移步<a href="https://github.com/alanzhang211/books" target="_blank" rel="noopener">github读书笔记</a>。多数是使用思维导图的方式产出，边读书，边画图效率很高，也方便日后温故。</li><li>其他技能（50分）：了解了金融和理财相关，理财方面大部分在指数定投这块；了解了信用卡一些功能。</li><li>健康方面（40分）：近3年，运动这块分数越来越低了。今年只跑了个 <em>梦想小镇半马</em>，真的是跑不动了，和PB相比，退步了近半小时。感觉还是15，16年是跑步黄金时期。当然，事事都有两面性。不过，<strong>健康</strong> 重中之重，还是要重视。</li><li>出游（95分）：感觉是完成度最高的一项。主要发生在上半年，从春节开始（第一次春节没回家过年）到五一。去了一值想去的日本，也算是完成了一个小小心愿（期间囧途，坎坷，也是人生阅历的提升）。然后就是济州岛，越南。相关游记也可以关注文末的公众号查看。</li><li>个人情感（30分）：这里要感谢亲朋好友平时的帮助；这种事情还是要依靠自己，继续努力吧。</li></ul><h4 id="概括"><a href="#概括" class="headerlink" title="概括"></a>概括</h4><p>还是感觉没有很出彩的地方，19年过去了，给人的感觉有点疲惫。不知道是不是年纪上来的愿意。每天思考的东西多了，感觉压力大了。很庆幸的是发量还让人满意。</p><h3 id="20展望"><a href="#20展望" class="headerlink" title="20展望"></a>20展望</h3><ul><li>健康：锻炼，至少参加一次正规的跑步比赛。</li><li>公众号：保持公众号一月一篇的产出量，努力能够形成一个专栏体系（工作，生活，学习等题材不限）。写的东西能够被认可固然很好；但最终还是一句话：N年后，能够通过搜索引擎找到它。</li><li>工作技能方面：领域做专，毕竟年纪大了，再没有点核心竞争力的话，真的要回家种地了；读书笔记，每月产出读书总结。定个年度量化的小目标：12本。</li><li>生活：希望能够在杭州“安定”下来，有个自己的小屋。</li><li>出游：能够去一趟除了亚洲之外的其他国家玩一趟，其他都算是“超量”。</li><li>其他：能够形成自己的一套理财实践路线；给自己买一个大件犒劳自己(具体是什么还没定，可能是一台sony的微单吧)。</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;今年的总结从何说起？元旦一天假期，本来想不写了。想想还是将这个习惯传承下去的好。不做深层次的分析，只是个流水总结。&lt;/p&gt;
&lt;h3 id=&quot;19总结&quot;&gt;&lt;a href=&quot;#19总结&quot; class=&quot;headerlink&quot; title=&quot;19总结&quot;&gt;&lt;/a&gt;19总结&lt;/h3&gt;&lt;p&gt;按照惯例，总结之前先看看上一年给自己“提纲”-&lt;a href=&quot;http://alanzhang.me/2019/01/01/2018%E3%81%AE%E8%87%AA%E5%B7%B1/#more&quot;&gt;2018の自己&lt;/a&gt;中末尾提到。&lt;/p&gt;
    
    </summary>
    
      <category term="总结" scheme="http://alanzhang.me/categories/%E6%80%BB%E7%BB%93/"/>
    
    
      <category term="总结" scheme="http://alanzhang.me/tags/%E6%80%BB%E7%BB%93/"/>
    
      <category term="2019" scheme="http://alanzhang.me/tags/2019/"/>
    
  </entry>
  
  <entry>
    <title>Alluxio初探</title>
    <link href="http://alanzhang.me/2019/12/07/Alluxio%E5%88%9D%E6%8E%A2/"/>
    <id>http://alanzhang.me/2019/12/07/Alluxio初探/</id>
    <published>2019-12-07T09:54:03.000Z</published>
    <updated>2019-12-07T11:37:51.593Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>又到年底了，职场充斥着“裁员”、“优化”味道。前段时间所在公司也经历了一波，反正有那么几天周围的同事都无心工作。这周公司也算是“稳定”了，不过还是有些危机感。有时候，在反思这一年来自己工作的“亮点”。想了想，好像一直在“优化”的路上。这里的优化是和工作相关的，集群，存储，计算的治理占据了2019大半的“江山”。说来惭愧，好像也没实打实地落地成一个产品。</p><p>又到周末了，天气貌似不错。没有活动，自己看了看工作wiki，理了理工作内容。过程中，很多细节上的事情没有沉淀（虽然今年也依据工作内容输出了一点点想法），缺少细致的总结。导致现在很多事情让自己说，还是有很多不确定的细节。</p><a id="more"></a><h2 id="再看alluxio"><a href="#再看alluxio" class="headerlink" title="再看alluxio"></a>再看alluxio</h2><p>看到年初第一件事，集群拆分。主要工作是为了隔离ETL任务和实时任务(spark streaming或flink作业)。新的实时集群，只有计算资源，没有过多的存储。所以，问题就抽象成：计算资源隔离，存储资源共享（hdfs）问题。当时也做了简单的调研。最终采用了最快最直接的方式实现了。具体细节见：<a href="http://alanzhang.me/2019/03/15/%E9%9B%86%E7%BE%A4%E4%BC%98%E5%8C%96%E5%BF%83%E9%85%B8%E5%8E%86%E7%A8%8B/#more">集群优化心酸历程</a></p><p>有大半年没关注alluxio了，看了看官网。稳定版本已经从之前的<code>1.8.1</code>到了<code>2.1.0</code>，可见社区也是很活跃的。然后看到出了一本书《Alluxio：大数据统一存储原理与实践》。<br><img src="https://github.com/alanzhang211/blog-image/raw/master/2019/12/Alluxio_%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%BB%9F%E4%B8%80%E5%AD%98%E5%82%A8%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E8%B7%B5.jpg" alt="Alluxio：大数据统一存储原理与实践"></p><p>于是，买了一本拜读拜读。书不厚，大概花了一下午，简单过了下，有些章节泛读（或跳过）。将一些需要进一步探索的章节输出脑图。<br><img src="https://github.com/alanzhang211/blog-image/raw/master/2019/12/alluxio.jpg" alt="脑图"></p><p>整个书大概可以分3部分，一部分是原理性描述的（也是后续需要重点研究的）；另一部分，描述如何集成部署，这块可以放在以后读，和官网的文档对比了下，差不多（可以跳过）。其余部分，就是一些实践案例分享，一些场景分析（可以泛读，看看自己是否面临类似的问题）。</p><p><a href="https://docs.alluxio.io/os/user/stable/cn/Overview.html" target="_blank" rel="noopener">看看官方文档</a></p><h2 id="后续"><a href="#后续" class="headerlink" title="后续"></a>后续</h2><p>看了这本书后，对alluxio的一些核心概念产生了兴趣。当然，很多设计理念，世面上大数据框架都有涉及。比如：高可用；master-worker；缓存；时间窗口；缓存策略（LRU等）；远程过程调用等等，可见，底层的实现原理都是通的。于是，萌生了一些好奇，一些策略是如何在alluxio中实践的？</p><p>早期，在调研的时候没有好好去看实现细节。经过今天的梳理和反思，感觉是需要细致的去了解下。于是<code>fork</code>源码，打算花上几天理理代码思路。</p><hr><p>待续…</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;又到年底了，职场充斥着“裁员”、“优化”味道。前段时间所在公司也经历了一波，反正有那么几天周围的同事都无心工作。这周公司也算是“稳定”了，不过还是有些危机感。有时候，在反思这一年来自己工作的“亮点”。想了想，好像一直在“优化”的路上。这里的优化是和工作相关的，集群，存储，计算的治理占据了2019大半的“江山”。说来惭愧，好像也没实打实地落地成一个产品。&lt;/p&gt;
&lt;p&gt;又到周末了，天气貌似不错。没有活动，自己看了看工作wiki，理了理工作内容。过程中，很多细节上的事情没有沉淀（虽然今年也依据工作内容输出了一点点想法），缺少细致的总结。导致现在很多事情让自己说，还是有很多不确定的细节。&lt;/p&gt;
    
    </summary>
    
      <category term="大数据" scheme="http://alanzhang.me/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="大数据" scheme="http://alanzhang.me/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="2019" scheme="http://alanzhang.me/tags/2019/"/>
    
      <category term="Alluxio" scheme="http://alanzhang.me/tags/Alluxio/"/>
    
  </entry>
  
  <entry>
    <title>一些心酸经历</title>
    <link href="http://alanzhang.me/2019/10/31/%E4%B8%80%E4%BA%9B%E5%BF%83%E9%85%B8%E7%BB%8F%E5%8E%86/"/>
    <id>http://alanzhang.me/2019/10/31/一些心酸经历/</id>
    <published>2019-10-31T15:01:00.000Z</published>
    <updated>2019-10-31T15:03:02.444Z</updated>
    
    <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>近期在做spark 运行任务信息采集（便于后续的任务执行分析作准备），遇到一点问题：</p><ul><li>通过spark history server（下面统称：SHS）提供的restful api获取application信息，与通过yarn采集的application数据量不一致。</li><li>采集几天，偶尔出现SHS restful api无数据返回问题。</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">运行环境</span><br><span class="line">hadoop：hadoop-2.6.0-cdh5.13.0</span><br><span class="line">spark：spark-2.1.1-bin-cdh5.13</span><br><span class="line">jdk：jdk1.8.0_74</span><br></pre></td></tr></table></figure><a id="more"></a><h2 id="处理"><a href="#处理" class="headerlink" title="处理"></a>处理</h2><h4 id="数据不一致问题"><a href="#数据不一致问题" class="headerlink" title="数据不一致问题"></a>数据不一致问题</h4><p>针对第一个数据不一致问题，主要是采集的维度不同导致。</p><ul><li>yarn请求api：/ws/v1/cluster/apps?finishedTimeBegin={0}&amp;finishedTimeEnd={1}</li><li>SHS请求api：/api/v1/applications?minDate=%s&amp;maxDate=%s&amp;status=completed<br>yarn以application结束时间采集，shs以application开始时间采集(minDate和maxDate都是和startTime对比）。</li></ul><p>spark-2.1.1源码：<br><img src="https://github.com/alanzhang211/blog-image/raw/master/2019/10/spark-2.1.1.png" alt="spark-2.1.1"></p><p>spark-3.0源码：<br><img src="https://github.com/alanzhang211/blog-image/raw/master/2019/10/spark-3.0.png" alt="spark-3.0"></p><p>对比返现，v3.0多了针对application结束时间采集进行获取。</p><h4 id="解决"><a href="#解决" class="headerlink" title="解决"></a>解决</h4><p>由于平台不会升级spark。所以，在采用restful api采集的时候，minDate 偏移量向前推1-2天。然后再和上一次抓去的applicationId进行去重处理，保证误差最小化。</p><h3 id="SHS无数据返回问题"><a href="#SHS无数据返回问题" class="headerlink" title="SHS无数据返回问题"></a>SHS无数据返回问题</h3><h4 id="现象"><a href="#现象" class="headerlink" title="现象"></a>现象</h4><p>某天返现sparkUI页面无响应，类似下图：</p><p><img src="https://github.com/alanzhang211/blog-image/raw/master/2019/10/SHS.png" alt="SHS"></p><p>查看后台采集SHS，也是直接返回了一个html页面内容。推测应该是SHS的jetty无法转发相应的request到指定handler，给了个默认的页面。</p><p>从服务器上dump了jvm堆情况：</p><p><img src="https://github.com/alanzhang211/blog-image/raw/master/2019/10/heap.png" alt="heap"></p><p>可以看到此时SHS内存中大部分是<code>org.eclipse.jetty.server.handler.ContextHandlerCollection</code>对象，可能理解。因为SHS内置jetty就是通过<code>ContextHandlerCollection</code>集合存放各种request请求。然后依据不同的uri转发到不同的handler上进行处理。在看下内存占用，大概9.5GB。</p><p>第二大的对象是<code>org.apache.spark.deploy.history.HistoryServer</code>，占用内存大概3.3GB。这个主要是实现对eventLog进行解析，封装成sparkUI对象，然后再缓存到cache中。</p><p>这里的核心对象sparkUI就是我们再spark web ui上看到的一个spark application的信息。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">val environmentListener: EnvironmentListener,</span><br><span class="line">val storageStatusListener: StorageStatusListener,</span><br><span class="line">val executorsListener: ExecutorsListener,</span><br><span class="line">val jobProgressListener: JobProgressListener,</span><br><span class="line">val storageListener: StorageListener,</span><br><span class="line">val operationGraphListener: RDDOperationGraphListener</span><br></pre></td></tr></table></figure></p><p>以上，每一个Listener都是一个监听器，来处理更新application对应的environment、storage、executor、job、stage、task信息。</p><p>第三个是<code>JobProgressListener</code>，大概2.1GB。一个spark application对应多个job，一个job对应多个stage，一个stage对应多个task。所以，这个listenter是主要对象。在使用restful api抓去job，stage、task的时候，都依赖这个。</p><p>那么，看完了内存分布，在回答问题。之所以api无响应，可能是jetty无法找到对应的handler，无法请求到某个application对应的sparkUI。</p><h4 id="解决-1"><a href="#解决-1" class="headerlink" title="解决"></a>解决</h4><p>我们回到源码开看下，在包：<code>org.apache.spark.status.api.v1 有ApiRootResource</code>类。这个就是api的controller，可以看到很多熟悉的url。</p><p><img src="https://github.com/alanzhang211/blog-image/raw/master/2019/10/api.png" alt="api"></p><p>截取了部分，看到每个请求都是new了一个封装类，然后通过withSparkUI获取一个sparkUI。这个ui就是从historyserver 缓存cache中拿。</p><p><strong>再看看采集SHS的实现</strong><br><img src="https://github.com/alanzhang211/blog-image/raw/master/2019/10/taskv1.png" alt="taskv1"></p><p>比如上面，application、job、stage、task 分成4个异步线程处理。通过上面的分析可知，每次api请求都需要依赖sparkUI对象，而这个对象是从SHS缓存中获取的。如果缓存失效会刷新缓存。<br>因此，4个异步线程会导致频繁的刷新缓存，导致SHS负载增加。</p><p><strong>介于这个原因，优化了采集实现逻辑</strong><br><img src="https://github.com/alanzhang211/blog-image/raw/master/2019/10/taskv2.png" alt="taskv2"></p><p>在采集指定区间application后，通过一个批量采集task完成对job、stage、task信息的抓去。这样，就较少了缓存cache的失效次数。减轻了SHS对eventLog的解析再cache过程。</p><p>优化后的效果比较明显，比异步处理快很多。之前4个任务采集一天内的数据要跑2-3小时，改造后也就1小时左右。而且也没出现过SHS无响应的问题。</p><hr><p>其实，回过头来想想。在没有认清SHS 实现原理的基础上，本来想异步加快采集处理，结果却适得其反。这些问题其实在设计初就应该刨根问底。</p><p>另外，在此期间也对LinkedIn的dr-elephant也做了了解。同样有作业采集，在针对Spark的抓取上，dr-elephant有2套实现，一个是FSFetcher(直接解析eventLog，省去了SHS解析过程)；另一个SparkRestClient（采用restful api + log）的方式，先拿到一个区间内的application，然后在看里application信息，难道对应的eventlog。</p><p>对比之下，就是将“batchFetcherTask”变成了访问hdfs获取日志，解析日志的过程。进而减轻了SHS的压力。</p><p>有兴趣的可以看下源码，比较简洁：<a href="https://github.com/linkedin/dr-elephant/tree/master/app/com/linkedin/drelephant/spark/fetchers" target="_blank" rel="noopener">spark-fetchers</a></p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h2&gt;&lt;p&gt;近期在做spark 运行任务信息采集（便于后续的任务执行分析作准备），遇到一点问题：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;通过spark history server（下面统称：SHS）提供的restful api获取application信息，与通过yarn采集的application数据量不一致。&lt;/li&gt;
&lt;li&gt;采集几天，偶尔出现SHS restful api无数据返回问题。&lt;/li&gt;
&lt;/ul&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;运行环境&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;hadoop：hadoop-2.6.0-cdh5.13.0&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;spark：spark-2.1.1-bin-cdh5.13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;jdk：jdk1.8.0_74&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
      <category term="大数据" scheme="http://alanzhang.me/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="大数据" scheme="http://alanzhang.me/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="2019" scheme="http://alanzhang.me/tags/2019/"/>
    
      <category term="spark" scheme="http://alanzhang.me/tags/spark/"/>
    
  </entry>
  
  <entry>
    <title>居然对理财产生了兴趣</title>
    <link href="http://alanzhang.me/2019/09/01/%E5%B1%85%E7%84%B6%E5%AF%B9%E7%90%86%E8%B4%A2%E4%BA%A7%E7%94%9F%E4%BA%86%E5%85%B4%E8%B6%A3/"/>
    <id>http://alanzhang.me/2019/09/01/居然对理财产生了兴趣/</id>
    <published>2019-09-01T14:09:01.000Z</published>
    <updated>2019-09-01T16:02:01.863Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://github.com/alanzhang211/blog-image/raw/master/2019/09/%E4%B8%8B%E9%9B%A8%E5%A4%A9.png" alt="下雨天"></p><blockquote><p>周末下了2天的雨，雨天适合看书，适合施展“懒人”模式。晚上，约了大学的朋友吃了个饭。回来的路上，透过车窗依旧下着雨。</p></blockquote> <a id="more"></a><p><img src="https://github.com/alanzhang211/blog-image/raw/master/2019/09/%E7%89%9B%E6%8E%92.png" alt="牛排"></p><p><img src="https://github.com/alanzhang211/blog-image/raw/master/2019/09/%E9%9D%A2%E5%8C%85.png" alt></p><p>不知道是不是上了年纪还是怎样，最近总会想一些事情。想着想着，就开始“天马行空”，似乎有太多需要考虑的事情。最近很流行一个词“太难了”。距离上次梳理发文，似乎很长一段时间，但为什么感觉过的好快。</p><p>最近，强迫自己看一些英文原版书籍，做了一些翻译的工作。看一些大数据底层相关的东西，看着看着就掉进去了，然后在<code>谷歌学术</code>搜一些论文之类的看。</p><ul><li>Flink很火，看了最新出版的《Stream Processing with Apache Flink》。翻译了前2章，主要介绍流处理系统的一些概念原理。书的后面就是围绕Flink开发展开。暂且没翻译，后续待更新。</li><li>然后，顺藤摸瓜，发现一本大神们推荐的一本书《Streaming Systems》。这本书蛮“重”。也是我后续主要啃的对象。</li></ul><p><em>上述内容会更新到github上：<a href="https://github.com/alanzhang211/books" target="_blank" rel="noopener">https://github.com/alanzhang211/books</a> 欢迎围观</em></p><p>某一天，无意中看到一篇文章。一篇讲述某某IT男如何实现<code>财务自由</code>的。发现，自己似乎除了专业知识外需要具备些其他的技能，而这些技能似乎比较匮乏。没错，这就是<code>理财</code>。</p><p>以前，无脑式的将闲钱投到p2p和一些货币基金里。现在p2p暴雷，有些短期空闲资金就不知道怎么更好地周转。最近，人民币贬值，贸易战升级等。世界经济似乎在去年就开始恶化。</p><p>然后，看看自己握在手里的钱一天天贬值。所以，开始想去了解经济体系，了解相关的理财。</p><p>看了一些公众号，快速的建立了一些理财基本体系。知道什么是<code>生钱资产</code>、<code>什么是耗钱资产</code>、<code>什么是其他资产</code>。现在火热的黄金，其实就是一种其他资产，获利就是通过差价获得，这个差价或为正，或为负。作为对冲经济风险的黄金，也是最近比较火热的投资工具（上半年涨幅30%+）。但这是一种高风险的投资，想要实现<code>财务自由</code>,想通过短期的投机是不行的。于是，这2天开始去了解企业（一个高性价比的理财工具）。当然，还有很多其他理财工具，这里不在点出，可看下图：</p><p><img src="https://github.com/alanzhang211/blog-image/raw/master/2019/09/%E7%90%86%E8%B4%A2.png" alt="理财"></p><p>针对企业，如何变成了理财工具？其实也很简单，最能想到的就是企业的股票，成为企业的股东，通过股票来获取回报；另一方面，你的跳槽涨薪水，也是一种借助企业来实现回报的过程。所以，如果了解了企业，你将实现更好的理财渠道。而要想了解好一家企业，怎么去了解？简单又直观的方式就是通过公司的财务报表来实现。</p><p>这里，我又延伸看了一本《一本书读懂财务报表》。这本书大概可以分2部分看，前半部分讲述了三种报表：<code>资产负债表</code>、<code>利润表</code>、<code>现金流报表</code>。前2个可以看出一家企业的运营状况（怎么生存的）；后一个可以看出企业的风险状况（是否能持续经营下去）。后半部分，围绕这3种报表，给出了实际对比案例，帮助读者去分析企业。后半部分值得多次读。</p><p>同样，自己也列了个脑图。书中的概念比较多，长得也比较像，需要多看几遍。</p><p><img src="https://github.com/alanzhang211/blog-image/raw/master/2019/09/%E4%B8%80%E6%9C%AC%E4%B9%A6%E8%AF%BB%E6%87%82%E8%B4%A2%E5%8A%A1%E6%8A%A5%E8%A1%A8.png" alt="一本书读懂财务报表"></p><p>毕竟，绝大多数人的工资总会到达峰顶，不会点理财。到达中年之后，各种压力，单凭工资是远远不够的，所以，理财学习要赶早。<code>复利</code>的计算公式<code>复利公式：最终收益=本金*（1+收益率）^时间</code> 。时间会让你的收益发生翻天覆地的变化。</p><hr><p><em>路还很长，学习的还有很多，待续…</em></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;https://github.com/alanzhang211/blog-image/raw/master/2019/09/%E4%B8%8B%E9%9B%A8%E5%A4%A9.png&quot; alt=&quot;下雨天&quot;&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;周末下了2天的雨，雨天适合看书，适合施展“懒人”模式。晚上，约了大学的朋友吃了个饭。回来的路上，透过车窗依旧下着雨。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="杂谈" scheme="http://alanzhang.me/categories/%E6%9D%82%E8%B0%88/"/>
    
    
      <category term="2019" scheme="http://alanzhang.me/tags/2019/"/>
    
      <category term="理财" scheme="http://alanzhang.me/tags/%E7%90%86%E8%B4%A2/"/>
    
  </entry>
  
  <entry>
    <title>集群治理之存储治理篇</title>
    <link href="http://alanzhang.me/2019/07/20/%E9%9B%86%E7%BE%A4%E6%B2%BB%E7%90%86%E4%B9%8B%E5%AD%98%E5%82%A8%E6%B2%BB%E7%90%86%E7%AF%87/"/>
    <id>http://alanzhang.me/2019/07/20/集群治理之存储治理篇/</id>
    <published>2019-07-19T16:01:05.000Z</published>
    <updated>2019-07-19T16:11:32.926Z</updated>
    
    <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>转眼间，七月过去一半有余。感觉时间过的好快，上周末还在和小伙伴讨论去哪玩，这又到周末了。回头看看，距离上篇文章差不多过去一个月。是时候总结下这一个月干了点啥了。</p><h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>自从入了数据的坑，感觉有做不完的优化。和以前做业务系统不同，之前，更多的是被源源不断的业务需求砸晕。而如今，做基础数据建设，每天都在想法设法优化数据，优化集群。怎么把数据的价值体现的更好上。</p><p>最近忙着搞数据治理。好像，这几天都在发送“账单”，催用户去处理数据。那么，有人会问：这是问什么呢？首先，数据有进无出。再大的存储系统也迟早会爆满。而且，从公司投入成本来算。没必要对一些冷数据或无用的数据投入过多的存储。</p><p>在说说，如果一味的以堆加机器的方式来弥补存储的不足。一方面，成本增加；另一方面，运维的成本也会增加。每天路过大数据运维同事旁边，拍拍肩膀：“今周打算加多少机器？”。对于运维同学来说，不也是很尴尬的一件事么？加机器，重复而无聊。虽说可以使用自动化部署，但是这种只增无减必定会带来维护成本上的“熵”增。</p><h1 id="措施"><a href="#措施" class="headerlink" title="措施"></a>措施</h1><p>面临这些囧状，对于数据的治理就迫在眉睫。就像人有生老病死，数据同样也有产生和消亡的过程。那么，数据就是有“生命”的实体。</p><hr><p><em>如何开展数据治理呢？</em></p><hr><a id="more"></a><p><img src="https://github.com/alanzhang211/blog-image/raw/master/2019/07/%E4%BC%81%E4%B8%9A%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_970aee49-1db9-4c80-a2b3-6bce60bdb419.png" alt="数据治理"></p><h2 id="生命周期"><a href="#生命周期" class="headerlink" title="生命周期"></a>生命周期</h2><p>首先，要赋予数据生命，涉及到生命周期管理，这是贯穿整个数据链路上的。针对不同等级的数据设定不同的“生命”长短。过期的表删除，冷备归档，最终销毁。</p><h2 id="账单"><a href="#账单" class="headerlink" title="账单"></a>账单</h2><p>其次，要使用户对数据有感知，让用户知道自己使用的数据资产情况。那么，就会抽象出另一个概念“存储账单”。说到这，你可以理解为用户使用的存储成本计费。这样一来，将无感知物理存储，转变为更贴于生活的成本计费。比如：100G每天计费1元。那么，用户就会知道自己的表大概一天使用多少钱。只要谈到“钱”，一般人都不会轻视，“壕”哥除外。进行个人日账单，部门周账单的推送。</p><p><img src="https://github.com/alanzhang211/blog-image/raw/master/2019/07/WechatIMG48.jpeg" alt="个人账单"></p><p><img src="https://github.com/alanzhang211/blog-image/raw/master/2019/07/WechatIMG47.jpeg" alt="部门账单"></p><h2 id="数据行为分析"><a href="#数据行为分析" class="headerlink" title="数据行为分析"></a>数据行为分析</h2><p>再者，有了上面的<code>生命周期</code>：可以实现用户自助管理自己数据生命，设置不同的生命周期，进行无用表的删除。同样，也可以对数据进行恢复。<code>存储账单</code>：直观的体现数据成本，督促用户治理数据。</p><p>那么，似乎还需要给用户提供治理建议。这么一来就有了关于数据行为分析的概念。简单来说就是数据的增长（用户可以重点关注增长过快的数据），数据的访问情况（用户可以区分冷热数据）。其底层，会依赖hdfs的一些系统数据和metastore的数据。技术上，就是通过hdfs的fsimage分析存储目录的最近访问时间和存储目录大小等，再结合hive的metastore元数据信息，给出表的一些行为表现。从而，给予用户一些指导作用。</p><p>经历过数据治理的同学，一般都会被用户质问：</p><ul><li>这个表为什么没用，最近什么时候访问的？</li><li>我用的很多么，我业务就需要啊。</li><li>能给出优化建议么？<br>等等。</li></ul><p>所以，有这个数据行为分析展示。咱们治理的同学说话也有了底气不是么？</p><h1 id="效果"><a href="#效果" class="headerlink" title="效果"></a>效果</h1><p>大概治理了2周，公司的数据量从之前的接近12PB降低到现在的10PB不到，降幅在16.7%。同时，用户也接受了<code>表生命周期</code>这个概念，能够主动去设置表生命周期来管理表。</p><h1 id="不足"><a href="#不足" class="headerlink" title="不足"></a>不足</h1><ul><li>用户还是需要有更强的数据意识，当然，做业务的还是业务为重，这也不能怪他们。</li><li>缺少了点奖罚措施，或者说是治理委员会的一种治理制度规范。</li><li>在自动化治理上，工具还是欠缺。</li></ul><h1 id="改进"><a href="#改进" class="headerlink" title="改进"></a>改进</h1><ol><li><p>首先，希望在未来能够从数据源头做起，提高数据质量，避免不必要的加工环节，优化ETL链路（依赖表的血缘）。如果有自动化的工具，可以检测到数据链路，预测给出最优链路是再好不过的了。</p></li><li><p>其次，就是跟完善的数据行为分析和优化建议。结合各个指标的TopN进行治理。</p></li><li><p>然后，就是数据的准确唯一性，对判断依据统一化。</p></li><li><p>再者，加大“曝光度”。对数据大户，和数据使用不合理的用户增加其曝光度。这样，推动起来更高效。</p></li><li><p>最后，能够实现数据配额的管理，对部门使用数据量严格把控。</p></li></ol><p><em>还有很多很多….欢迎交流！</em></p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h1&gt;&lt;p&gt;转眼间，七月过去一半有余。感觉时间过的好快，上周末还在和小伙伴讨论去哪玩，这又到周末了。回头看看，距离上篇文章差不多过去一个月。是时候总结下这一个月干了点啥了。&lt;/p&gt;
&lt;h1 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h1&gt;&lt;p&gt;自从入了数据的坑，感觉有做不完的优化。和以前做业务系统不同，之前，更多的是被源源不断的业务需求砸晕。而如今，做基础数据建设，每天都在想法设法优化数据，优化集群。怎么把数据的价值体现的更好上。&lt;/p&gt;
&lt;p&gt;最近忙着搞数据治理。好像，这几天都在发送“账单”，催用户去处理数据。那么，有人会问：这是问什么呢？首先，数据有进无出。再大的存储系统也迟早会爆满。而且，从公司投入成本来算。没必要对一些冷数据或无用的数据投入过多的存储。&lt;/p&gt;
&lt;p&gt;在说说，如果一味的以堆加机器的方式来弥补存储的不足。一方面，成本增加；另一方面，运维的成本也会增加。每天路过大数据运维同事旁边，拍拍肩膀：“今周打算加多少机器？”。对于运维同学来说，不也是很尴尬的一件事么？加机器，重复而无聊。虽说可以使用自动化部署，但是这种只增无减必定会带来维护成本上的“熵”增。&lt;/p&gt;
&lt;h1 id=&quot;措施&quot;&gt;&lt;a href=&quot;#措施&quot; class=&quot;headerlink&quot; title=&quot;措施&quot;&gt;&lt;/a&gt;措施&lt;/h1&gt;&lt;p&gt;面临这些囧状，对于数据的治理就迫在眉睫。就像人有生老病死，数据同样也有产生和消亡的过程。那么，数据就是有“生命”的实体。&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;如何开展数据治理呢？&lt;/em&gt;&lt;/p&gt;
&lt;hr&gt;
    
    </summary>
    
      <category term="大数据" scheme="http://alanzhang.me/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="大数据" scheme="http://alanzhang.me/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="数据治理" scheme="http://alanzhang.me/tags/%E6%95%B0%E6%8D%AE%E6%B2%BB%E7%90%86/"/>
    
      <category term="集群治理" scheme="http://alanzhang.me/tags/%E9%9B%86%E7%BE%A4%E6%B2%BB%E7%90%86/"/>
    
  </entry>
  
  <entry>
    <title>聊聊数据治理</title>
    <link href="http://alanzhang.me/2019/06/16/%E8%81%8A%E8%81%8A%E6%95%B0%E6%8D%AE%E6%B2%BB%E7%90%86/"/>
    <id>http://alanzhang.me/2019/06/16/聊聊数据治理/</id>
    <published>2019-06-16T08:20:03.000Z</published>
    <updated>2019-06-18T18:00:47.824Z</updated>
    
    <content type="html"><![CDATA[<p>最近几个月，公司人员变动挺大的。可能每年的这个时候，每家公司都差不多吧。上半年的4-5月份，下半年的8-9月份。（这里只是泛指，自己的2次跳槽都发生在这个区间）。自己所处的数据部，也逐渐有部分员工流失。人员变更，带来了组织上的微调整。就在6月初，tl也提交了辞职申请。这里不好对他人做过多的议论。不过，tl给了我不少的职场意见。</p><p>自己从事数据相关职位，算算差不多3年了吧（从2016.6-至今）。感觉到自己似乎还是个吸水量很足的海绵。从上家公司初次接触数据平台，然后部门整个团队也是在摸索中不断构建数据产品组件（调度、元数据、数据开发、数据交换、可视化报表等。要说数据报表，起初是从很早之前fine report开始接触一些报表类处理，然后致使我去做数据这块的东西）。</p><p>当时，整个团队缺少点资深的数据技术或者数据产品。所以，做出来的有时候就是拍脑袋的事，然后过了不久，就重新构建，或者推到重来。</p><p>这似乎可以看作是数据平台建设的第一个阶段：跑起来再说。第二家，也就是目前的公司。算是在第二阶段：统一化、规范化。至于第三阶段：服务化，统一的数据中台。目前还没到吧。<br><em>（以上3个阶段不是权威概念，只是我个人的理解，然后给了个词表述）</em></p><a id="more"></a><p>回来说说本文的主题<strong>数据治理。</strong></p><p>前段时间，处理公司的集群优化。处于中期公司都会面临的一些问题，对于集群治理，数据质量等。不管是存储的治理，还是计算资源的治理，应该都是数据治理的范畴。</p><p>然后，不久前看了一本关于数据管理的书籍《DAMA-DMBOK》。一本定义一套数据管理原则的书籍。其中，讲述了很多概念，包括数据管理，数据治理，以及数据道德的东西。<br><img src="https://github.com/alanzhang211/blog-image/raw/master/2019/06/data.png" alt="大纲"></p><p>有兴趣的同学可以看一看，比较厚的书籍。在线电子书地址：<a href="https://learning.oreilly.com/library/view/dama-dmbok-data-management/9781634622479/" target="_blank" rel="noopener">https://learning.oreilly.com/library/view/dama-dmbok-data-management/9781634622479/</a></p><p> <em>注册账户，免费10天适用</em></p><p>本书，就是以数据治理为中心，逐步展开讲解。<br><img src="https://github.com/alanzhang211/blog-image/raw/master/2019/06/data1.png" alt="治理"><br><code>数据治理</code>是在<code>数据管理</code>过程中，对其的监控和控制。伴随着就有<code>数据质量</code>来衡量和评估。这三个过程是相互依赖，相互补充的。</p><p><strong>那么，怎么才能做好数据治理呢？</strong></p><p>在我经历的过程中，<code>数据治理</code>这个说简单也简单，说复杂也复杂。简单来说，数据治理么，就是对数据整个生命周期进行管理，包括：数据的产出，数据的加工，数据应用，数据下线，数据删除等过程。</p><p>复杂的说，其中就会牵扯到很多数据，不单单指数据的生命周期过程。可能还会延伸出一些其他元数据的处理。如：表治理-涉及到存储管理；yarn任务治理-涉及到集群计算资源的治理。进而衍生出后面的存储账单、计算账单等。</p><p>说到账单，第一感受就是要<strong>收费</strong>了。收费的目的就是为了给用户一种压力，让用户知道，你在跑任务，存储数据的时候是在花钱的。给用户这种意识，就会遏制一些资源浪费的情况。比如：一些僵尸表（近N天无访问），无用表（任务业务已经下线），过期表（数据生命周期已经过期），像这些存储的数据，是可以进行回收销毁的。再比如：一些在yarn上跑的大车任务（耗时较长，占用vcore过多，可以抽象出一种计算单元的概念），还有一些输入表和输出表数据无变化或变化不大的etl过程，这些都是需要治理的任务。</p><p>前几天，和朋友聊这块的治理。真的，要想治理好。不单单在平台底层方面把数据做好（各种监控数据，监控指标）。同样，也需要数据委员会（这里泛指公司领导层）的支持，并推动各级实施。</p><p>然后，可能会引入一些类似<code>健康分</code>的概念。当你的数据在某种统一规则下，不满足。就会扣除相应的分数。当达到一定阀值，就会限制任务使用资源或直接遏制任务运行。这就迫使用户去提高健康分。从而向集群争取更多的资源。</p><p>当然，这种资源也是不能无休止的申请。那么，前面说的账单就起作用了。这个可以以收费的方式督促用户节约资源。</p><p>目前，公司也一直在做这块的东西。但是持续了很久，还是没能很好的落地实施。为什么？这个确实要很好地反思。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">就目前观察来看，有以下几方面：</span><br><span class="line">1. 底层数据的准确性有待提高。迫使，实施者存在疑虑，无法很好的推广。</span><br><span class="line">2. 流程上没有打通，没有和平台进行融合。</span><br><span class="line">3. 对用户透明，用户无感知这些资源的消耗带来的不足。致使资源的滥用。</span><br><span class="line">4. 资源管控力度不够。</span><br><span class="line">5. 缺乏有效的治理工具，比较零散，不易做成闭环。</span><br></pre></td></tr></table></figure><p>最近，在处理公司这块。发现了上面一些问题。感受到，治理这块真的是个难啃的<code>骨头</code>。每天大数据群里都会有类似于“任务跑不动了”、“数据查不出来”等。</p><p>所以，第一步就是将计算、存储资源如何很好的反馈给用户。接着就是，怎么推动用户去调整，集群去优化。然后，就要有相关的反馈机制（如：优化跟踪等）。进而可以持续地优化。</p><hr><p>大半夜写这些，也是想抒发下自己的一些感慨。同时，也是梳理一下做了什么，需要做什么，怎么去做。虽然，不够细致，但是也是自我梳理的过程。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;最近几个月，公司人员变动挺大的。可能每年的这个时候，每家公司都差不多吧。上半年的4-5月份，下半年的8-9月份。（这里只是泛指，自己的2次跳槽都发生在这个区间）。自己所处的数据部，也逐渐有部分员工流失。人员变更，带来了组织上的微调整。就在6月初，tl也提交了辞职申请。这里不好对他人做过多的议论。不过，tl给了我不少的职场意见。&lt;/p&gt;
&lt;p&gt;自己从事数据相关职位，算算差不多3年了吧（从2016.6-至今）。感觉到自己似乎还是个吸水量很足的海绵。从上家公司初次接触数据平台，然后部门整个团队也是在摸索中不断构建数据产品组件（调度、元数据、数据开发、数据交换、可视化报表等。要说数据报表，起初是从很早之前fine report开始接触一些报表类处理，然后致使我去做数据这块的东西）。&lt;/p&gt;
&lt;p&gt;当时，整个团队缺少点资深的数据技术或者数据产品。所以，做出来的有时候就是拍脑袋的事，然后过了不久，就重新构建，或者推到重来。&lt;/p&gt;
&lt;p&gt;这似乎可以看作是数据平台建设的第一个阶段：跑起来再说。第二家，也就是目前的公司。算是在第二阶段：统一化、规范化。至于第三阶段：服务化，统一的数据中台。目前还没到吧。&lt;br&gt;&lt;em&gt;（以上3个阶段不是权威概念，只是我个人的理解，然后给了个词表述）&lt;/em&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="大数据" scheme="http://alanzhang.me/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="大数据" scheme="http://alanzhang.me/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="数据治理" scheme="http://alanzhang.me/tags/%E6%95%B0%E6%8D%AE%E6%B2%BB%E7%90%86/"/>
    
  </entry>
  
  <entry>
    <title>突然想写点什么</title>
    <link href="http://alanzhang.me/2019/04/21/%E7%AA%81%E7%84%B6%E6%83%B3%E5%86%99%E7%82%B9%E4%BB%80%E4%B9%88/"/>
    <id>http://alanzhang.me/2019/04/21/突然想写点什么/</id>
    <published>2019-04-21T07:32:09.000Z</published>
    <updated>2019-04-21T07:34:06.089Z</updated>
    
    <content type="html"><![CDATA[<p>这两个周末有点昏昏沉沉，五一快到了，感觉提不起精神。约了同伴去越南5日游。这两天开始订酒店，规划路线（机票签证已出），想轻松点，不想太折腾。<br>暂定如下：<br><img src="https://github.com/alanzhang211/blog-image/raw/master/2019/04/WechatIMG49.jpeg" alt="旅游路线"></p><a id="more"></a><h3 id="离合"><a href="#离合" class="headerlink" title="离合"></a>离合</h3><p>中午，翻了翻豆瓣小组，看看其他人5.1都去哪。无意间看到了一个帖子。题目引起了我的关注<code>现在恶化了，三十岁的我得了癌症，说说过去和现在</code>。想着自己也是一只脚要踏进30大门的人，点进去看了看。帖子是16年的，lz在16.9月离开。回帖16年至今近2000，有些回贴的账号已经显示<code>已注销</code>。评论中充满了祝福。突然间，对离合这东西，又品味了一番。这两天关于<code>上海17岁男孩跳桥</code>也生了热搜。</p><p>整个人生的旅途需要自己把控，当然，很多也不如人愿意。生活中各种羁绊也是值得慢慢品味。然而，很多人总是浑浑噩噩。n年后回顾自己，做了些什么？好像就是吃饭睡觉了么？</p><p>然后，也开始自省4月份的自己，公司时间大部分朝十晚九。每日到公司，罗列着每日，每周规划。现在看了下，也还说的过去。但也暴露了一些事情。<code>自我成长</code>几乎为0。读书计划也快断了一个月，没有产出。然后，反省这个月做了些什么，好像一直在处理工作琐碎。<br><img src="https://github.com/alanzhang211/blog-image/raw/master/2019/04/WechatIMG48.jpeg" alt></p><h3 id="近况"><a href="#近况" class="headerlink" title="近况"></a>近况</h3><p>跟着身边的同事，<code>玩卡</code>。额度，权益。也关注了一些玩卡的公众号。也算是对信用卡有了进一步了解。学习了一点点通过卡来优化提升生活质量。</p><p>前不久，也在youtube上看到了有人放出自己<code>旅游世界地图</code>，用了短视频记录自己旅行。很好的一中回忆录。n年后，看到自己的世界足迹，还是蛮幸福的。自己也萌生了些想法，旅行是一个<code>不断认知的过程</code>。人生的旅途是<code>终于遇到一个人，让你明白之前走过的路，是为了让你遇到那个TA</code>。</p><p>所以，每次出游，打算记录下来，绘制自己的世界地图。<br><img src="https://github.com/alanzhang211/blog-image/raw/master/2019/04/WechatIMG13.jpeg" alt="google"></p><h3 id="找点事"><a href="#找点事" class="headerlink" title="找点事"></a>找点事</h3><p>翻翻自己的年初计划，19年过了三分之一有余。<strong>多读书，少YY</strong>。近期，想的太多，行动太少。导致理想和现实的差距，让自己有些挫败感。然后连锁着就是自己的昏昏沉沉。周末，除了放松心情，品味生活，也是短期总结的时间。一周回顾，一个月回顾；接下来一周规划，一个月计划… 总得找点自己能够拿得出总结的。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;这两个周末有点昏昏沉沉，五一快到了，感觉提不起精神。约了同伴去越南5日游。这两天开始订酒店，规划路线（机票签证已出），想轻松点，不想太折腾。&lt;br&gt;暂定如下：&lt;br&gt;&lt;img src=&quot;https://github.com/alanzhang211/blog-image/raw/master/2019/04/WechatIMG49.jpeg&quot; alt=&quot;旅游路线&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="生活感悟" scheme="http://alanzhang.me/categories/%E7%94%9F%E6%B4%BB%E6%84%9F%E6%82%9F/"/>
    
    
      <category term="2019" scheme="http://alanzhang.me/tags/2019/"/>
    
      <category term="杂谈" scheme="http://alanzhang.me/tags/%E6%9D%82%E8%B0%88/"/>
    
  </entry>
  
  <entry>
    <title>集群优化心酸历程</title>
    <link href="http://alanzhang.me/2019/03/15/%E9%9B%86%E7%BE%A4%E4%BC%98%E5%8C%96%E5%BF%83%E9%85%B8%E5%8E%86%E7%A8%8B/"/>
    <id>http://alanzhang.me/2019/03/15/集群优化心酸历程/</id>
    <published>2019-03-15T10:12:11.000Z</published>
    <updated>2019-12-07T11:15:08.346Z</updated>
    
    <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>最近在做公司集群优化工作，现状是公司的离线集群跑着一些实时任务（flink和sparkstreaming）。有时候会因为晚上离线任务起来后，集群资源不够导致实时任务延迟等。为了解决这个问题，部署了一套实时集群，专门用来跑实时任务。从而将实时任务和离线任务进行隔离。</p><h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>目前，有些spark streaming任务需要读写hdfs或着操作hive表。那么如果要迁移这些任务，就需要满足实时集群可以访问离线集群的存储资源。鉴于这种场景，进行了相关调研。</p><a id="more"></a><h2 id="目标"><a href="#目标" class="headerlink" title="目标"></a>目标</h2><p>将离线集群中所有的实时任务迁移至实时集群进行管理。实现计算独立+存储共享，进而实现集群优化的目的。</p><h2 id="业界方案"><a href="#业界方案" class="headerlink" title="业界方案"></a>业界方案</h2><h3 id="Federation-Viewfs"><a href="#Federation-Viewfs" class="headerlink" title="Federation+Viewfs"></a>Federation+Viewfs</h3><p>参考：<a href="http://www.searchdoc.cn/hadoop/hadoop.apache.org/docs/r2.9.0/hadoop-project-dist/hadoop-hdfs/ViewFs.com.coder114.cn.html" target="_blank" rel="noopener">http://www.searchdoc.cn/hadoop/hadoop.apache.org/docs/r2.9.0/hadoop-project-dist/hadoop-hdfs/ViewFs.com.coder114.cn.html</a></p><p>hadoop 原生的解决方案。</p><p><img src="https://github.com/alanzhang211/blog-image/raw/master/2019/03/federation.png" alt="MultipleNamenodes"></p><p>优点：</p><ol><li>原生自带支持，无需二次开发。</li><li>系统兼容性好。</li></ol><p>缺点：</p><ol><li>需要客户端改动很多配置，如果新增节点，处理比较繁琐，扩展不方便。</li><li>需要修改客户端代码，由以前hdfs://xxx/，改为viewfs://xxx/。</li></ol><h3 id="Alluxio"><a href="#Alluxio" class="headerlink" title="Alluxio"></a>Alluxio</h3><p>官网：<a href="http://www.alluxio.org/" target="_blank" rel="noopener">http://www.alluxio.org/</a></p><p>Alluxio可以为那些大数据应用提供一个数量级的加速，同时它还提供了通用的数据访问接口。对于底层存储系统，Alluxio连接了大数据应用和传统存储系统之间的间隔，并且重新定义了一组面向数据使用的工作负载程序。</p><p>因Alluxio对应用屏蔽了底层存储系统的整合细节，所以任何底层存储系统都可以支撑运行在Alluxio之上的应用和框架。此外Alluxio可以挂载多种底层存储系统，所以它可以作为统一层为任意数量的不同数据源提供服务。<br><img src="https://github.com/alanzhang211/blog-image/raw/master/2019/03/alluxio.png" alt="Alluxio"></p><p>优点：</p><ol><li>易于扩展，支持多种存储。</li><li>可以优化spark的任务性能，加速数据处理。</li><li>代码开源：<a href="https://github.com/Alluxio/alluxio。" target="_blank" rel="noopener">https://github.com/Alluxio/alluxio。</a></li></ol><p>缺点：</p><ol><li>需要客户端依赖Alluxio，使用Alluxio的api访问hdfs数据。</li><li>对客户端不透明，需要调整数据接口即协议。</li><li>集群需要额外部署Alluxio，增加运维成本。</li></ol><h4 id="问题-1"><a href="#问题-1" class="headerlink" title="问题"></a>问题</h4><ol><li><p>alluxio如何感知底层文件系统变更？</p></li><li><p>alluxio如何保证数据的实时性？</p></li><li><p>如何保证数据一致性？</p></li></ol><h3 id="二次开发方案"><a href="#二次开发方案" class="headerlink" title="二次开发方案"></a>二次开发方案</h3><p>实现一个namenode代理，将客户端请求由逻辑路径路由到物理路径。</p><p>目前，了解到今日头条有实现类似的技术。</p><p>开源版本：<a href="https://github.com/bytedance/nnproxy" target="_blank" rel="noopener">https://github.com/bytedance/nnproxy</a></p><hr><h2 id="实际实施方案"><a href="#实际实施方案" class="headerlink" title="实际实施方案"></a>实际实施方案</h2><h3 id="hdfs-federation"><a href="#hdfs-federation" class="headerlink" title="hdfs federation"></a>hdfs federation</h3><p>借鉴hdfs federation的namenode横向扩展能力，以及资源隔离的特性。</p><p><img src="https://github.com/alanzhang211/blog-image/raw/master/2019/03/hdfs.png" alt="hdfs federation"></p><h4 id="hdfs-site-xml配置"><a href="#hdfs-site-xml配置" class="headerlink" title="hdfs-site.xml配置"></a>hdfs-site.xml配置</h4><p>hdfs-site.xml中增加多个nameservice（一个离线，一个实时）。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;</span><br><span class="line"></span><br><span class="line">&lt;!--Autogenerated by Cloudera Manager--&gt;</span><br><span class="line">&lt;configuration&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;dfs.nameservices&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;nameserviceoffline,nameserviceonline&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">(其他配置省略，直接从两个集群的hdfs-site.xml拷贝就好)</span><br><span class="line">......</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure></p><h3 id="测试用例"><a href="#测试用例" class="headerlink" title="测试用例"></a>测试用例</h3><table><thead><tr><th>用例</th><th>用例</th></tr></thead><tbody><tr><td>跨集群读hdfs</td><td>pass</td></tr><tr><td>跨集群写hdfs</td><td>pass</td></tr><tr><td>跨集群读hive表</td><td>pass</td></tr><tr><td>跨集群写hive表</td><td>pass</td></tr></tbody></table><h4 id="读写hdfs"><a href="#读写hdfs" class="headerlink" title="读写hdfs"></a>读写hdfs</h4><h5 id="测试代码"><a href="#测试代码" class="headerlink" title="测试代码"></a>测试代码</h5><h6 id="java"><a href="#java" class="headerlink" title="java"></a>java</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">public class JavaSparkHdfsExample &#123;</span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line">        SparkConf sparkConf = new SparkConf().setAppName(&quot;JavaSparkHdfsExample&quot;);</span><br><span class="line">        JavaSparkContext sc = new JavaSparkContext(sparkConf);</span><br><span class="line">//      JavaStreamingContext sc = new JavaStreamingContext(sparkConf, Durations.seconds(1));</span><br><span class="line">        JavaRDD&lt;String&gt; textFile = sc.textFile(&quot;hdfs://nameserviceoffline/tmp/zhq/kv1.txt&quot;);</span><br><span class="line">        JavaPairRDD&lt;String, Integer&gt; counts = textFile</span><br><span class="line">            .flatMap(s -&gt; Arrays.asList(s.split(&quot;,&quot;)).iterator())</span><br><span class="line">            .mapToPair(word -&gt; new Tuple2&lt;&gt;(word, 1))</span><br><span class="line">            .reduceByKey((a, b) -&gt; a + b);</span><br><span class="line">        try &#123;</span><br><span class="line">            FileSystem fs = FileSystem.get(new URI(&quot;hdfs://nameserviceoffline/tmp/zhq/kv2.txt&quot;),sc.hadoopConfiguration());</span><br><span class="line">            fs.delete(new Path(&quot;hdfs://nameserviceoffline/tmp/zhq/kv2.txt&quot;),true);</span><br><span class="line">            counts.saveAsTextFile(&quot;hdfs://nameserviceoffline/tmp/zhq/kv2.txt&quot;);</span><br><span class="line">        &#125; catch (IOException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125; catch (URISyntaxException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h6 id="spark-shell"><a href="#spark-shell" class="headerlink" title="spark-shell"></a>spark-shell</h6><p>在实时集群提交<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">$SPARK_HOME/bin/spark-submit \</span><br><span class="line">                --master yarn \</span><br><span class="line">                --deploy-mode cluster \</span><br><span class="line">                --executor-memory 512M \</span><br><span class="line">                --executor-cores  1 \</span><br><span class="line">                --conf spark.executor.extraClassPath=/opt/cloudera/parcels/CDH/jars/htrace-core-3.2.0-incubating.jar \</span><br><span class="line">                --conf spark.executorEnv.JAVA_HOME=/usr/zhq/java \</span><br><span class="line">                --conf spark.yarn.appMasterEnv.JAVA_HOME=/usr/zhq/java/ \</span><br><span class="line">                --conf spark.yarn.dist.files=/home/zhq/conf/hdfs-site.xml</span><br><span class="line">                --driver-memory 512M \</span><br><span class="line">                --queue root.sale_prod_etl.sla \</span><br><span class="line">                --verbose \</span><br><span class="line">                --name &quot;sparkdemo&quot; \</span><br><span class="line">                --class JavaSparkHdfsExample \</span><br><span class="line">                SparkDemo-1.0-SNAPSHOT.jar;</span><br></pre></td></tr></table></figure></p><p><strong>关键</strong>针对任务，提交参数中<code>spark.yarn.dist.files</code> 制定配置了federation的hdfs-site.xml。</p><h4 id="读写hive表"><a href="#读写hive表" class="headerlink" title="读写hive表"></a>读写hive表</h4><h5 id="测试代码-1"><a href="#测试代码-1" class="headerlink" title="测试代码"></a>测试代码</h5><h6 id="java-1"><a href="#java-1" class="headerlink" title="java"></a>java</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">public class JavaSparkHiveExample &#123;</span><br><span class="line">    // $example on:spark_hive$</span><br><span class="line">    public static class Record implements Serializable &#123;</span><br><span class="line">        private int key;</span><br><span class="line">        private String value;</span><br><span class="line">        public int getKey() &#123;</span><br><span class="line">            return key;</span><br><span class="line">        &#125;</span><br><span class="line">        public void setKey(int key) &#123;</span><br><span class="line">            this.key = key;</span><br><span class="line">        &#125;</span><br><span class="line">        public String getValue() &#123;</span><br><span class="line">            return value;</span><br><span class="line">        &#125;</span><br><span class="line">        public void setValue(String value) &#123;</span><br><span class="line">            this.value = value;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    // $example off:spark_hive$</span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line">        // $example on:spark_hive$</span><br><span class="line">        SparkConf sparkConf = new SparkConf().setAppName(&quot;JavaSparkHiveExample&quot;);</span><br><span class="line">        SparkSession spark = SparkSession</span><br><span class="line">            .builder()</span><br><span class="line">            .config(sparkConf)</span><br><span class="line">            .enableHiveSupport()</span><br><span class="line">            .getOrCreate();</span><br><span class="line">        spark.sql(&quot;SELECT * FROM ods.src_test&quot;).show();</span><br><span class="line">        // Aggregation queries are also supported.</span><br><span class="line">        spark.sql(&quot;SELECT COUNT(*) FROM ods.src_test&quot;).show();</span><br><span class="line"></span><br><span class="line">        //insert data</span><br><span class="line">        spark.sql(&quot;insert into ods.src_test select 1,&apos;val_1&apos;&quot;);</span><br><span class="line">        spark.sql(&quot;SELECT COUNT(*) FROM ods.src_test&quot;).show();</span><br><span class="line">        spark.stop();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h6 id="spark-shell-1"><a href="#spark-shell-1" class="headerlink" title="spark-shell"></a>spark-shell</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">$SPARK_HOME/bin/spark-submit \</span><br><span class="line">                --master yarn \</span><br><span class="line">                --deploy-mode cluster \</span><br><span class="line">                --executor-memory 512M \</span><br><span class="line">                --executor-cores  1 \</span><br><span class="line">                --conf spark.executor.extraClassPath=/opt/cloudera/parcels/CDH/jars/htrace-core-3.2.0-incubating.jar \</span><br><span class="line">                --conf spark.executorEnv.JAVA_HOME=/usr/zhq/java \</span><br><span class="line">                --conf spark.yarn.appMasterEnv.JAVA_HOME=/usr/zhq/java/ \</span><br><span class="line">                --conf spark.yarn.dist.files=/home/zhq/conf/hive-site.xml,/home/zhq/conf/hdfs-site.xml,/home/zhq/conf/core-site.xml \</span><br><span class="line">                --driver-memory 512M \</span><br><span class="line">                --queue root.sale_prod_etl.sla \</span><br><span class="line">                --verbose \</span><br><span class="line">                --name &quot;sparkdemo&quot; \</span><br><span class="line">                --class JavaSparkHiveExample \</span><br><span class="line">                SparkDemo-1.0-SNAPSHOT.jar;</span><br></pre></td></tr></table></figure><p>这里，同样通过<code>spark.yarn.dist.files</code> 重写spark运行参数。</p><ul><li><code>hive-site.xml</code>直接从离线集群拷贝。</li><li><code>hdfs-site.xml</code>是上面配置的hdfs federation。</li><li><code>core-site.xml</code>直接从离线集群拷贝，这里为了覆盖默认的实时集群的core-site.xml（因为spark hive 在写表的时候，默认是加载集群的core-site.xml中<code>fs.defaultFS</code>找hdfs目录的。当然，也可以直接程序中sparkcontent设置<code>fs.defaultFS</code>）。</li></ul><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>遇到问题还是要仔细分析问题本质，然后付诸实践。原理的东西，有时间还是要仔细推敲一下。比如：spark hive 中的<code>HiveClientImpl</code>实现。就会知道大概的一个sql执行过程，延伸到有关sql 解析和执行计划，如何分解成MR任务，然后落表的。很多细节需要理解，路途漫漫。</p><p>Alluxio方案也验证过，方案可行，需要注意的问题比较多，出现或多或少的问题主要还是不熟悉，有一定学习成本。</p><p>比如：</p><p><strong>报错</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Peer indicated failure: Plain authentication failed: User yarn is not configured for any impersonation. impersonationUser: hdfs</span><br></pre></td></tr></table></figure><p><strong>解决</strong>：需修改alluxio配置文件alluxio-site.properties，添加如下内容以实现yarn对其他用户的代理权限<code>alluxio.master.security.impersonation.yarn.users=*</code></p><hr><p>后面，会研究下<code>Alluxio</code>，这个“加速器”，前景貌似还不错，也欢迎一起交流讨论。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h2&gt;&lt;p&gt;最近在做公司集群优化工作，现状是公司的离线集群跑着一些实时任务（flink和sparkstreaming）。有时候会因为晚上离线任务起来后，集群资源不够导致实时任务延迟等。为了解决这个问题，部署了一套实时集群，专门用来跑实时任务。从而将实时任务和离线任务进行隔离。&lt;/p&gt;
&lt;h2 id=&quot;问题&quot;&gt;&lt;a href=&quot;#问题&quot; class=&quot;headerlink&quot; title=&quot;问题&quot;&gt;&lt;/a&gt;问题&lt;/h2&gt;&lt;p&gt;目前，有些spark streaming任务需要读写hdfs或着操作hive表。那么如果要迁移这些任务，就需要满足实时集群可以访问离线集群的存储资源。鉴于这种场景，进行了相关调研。&lt;/p&gt;
    
    </summary>
    
      <category term="大数据" scheme="http://alanzhang.me/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="大数据" scheme="http://alanzhang.me/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="2019" scheme="http://alanzhang.me/tags/2019/"/>
    
      <category term="集群优化" scheme="http://alanzhang.me/tags/%E9%9B%86%E7%BE%A4%E4%BC%98%E5%8C%96/"/>
    
  </entry>
  
  <entry>
    <title>2018の自己</title>
    <link href="http://alanzhang.me/2019/01/01/2018%E3%81%AE%E8%87%AA%E5%B7%B1/"/>
    <id>http://alanzhang.me/2019/01/01/2018の自己/</id>
    <published>2019-01-01T09:03:56.000Z</published>
    <updated>2019-02-26T15:14:20.373Z</updated>
    
    <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p><img src="https://github.com/alanzhang211/blog-image/raw/master/2018/12/WechatIMG128.jpeg" alt></p><p>又是一年一度的总结大会，朋友圈各种flag。有诙谐幽默的，有简单扼要的，有朴实无华的，等等。截取部分拼了个flag墙<br><img src="https://github.com/alanzhang211/blog-image/raw/master/2018/12/WechatIMG126.jpeg" alt="flag墙"></p><a id="more"></a><p><img src="https://github.com/alanzhang211/blog-image/raw/master/2018/12/WechatIMG125.jpeg" alt="flag墙"></p><p>回到自己，梳理自己的同时，回顾了一下去年的2017（参见：<a href="http://alanzhang.me/2017/12/31/%E6%88%91%E7%9A%842017/">我的2017</a>）看到末尾的2018展望。</p><ol><li>出游：完成度 60% 算是及格线。</li><li>持续沉淀：完成度80% 算是良好。</li><li>锻炼：完成度40% <strong>不合格，还重了几斤。</strong></li><li>其他：60% 及格线，中规中矩吧。</li></ol><h1 id="梳理2018"><a href="#梳理2018" class="headerlink" title="梳理2018"></a>梳理2018</h1><p>上面简单罗列了完成度，下面细化梳理各个环节。还是从轻松愉快的生活切入。</p><h2 id="生活"><a href="#生活" class="headerlink" title="生活"></a>生活</h2><h3 id="出游"><a href="#出游" class="headerlink" title="出游"></a>出游</h3><p>追忆了一下，好像今年出去玩的时间少了很多。最远的也就是十一国庆去了趟丽江，爬了个哈巴。其他嘛，零零星星点缀了一点。总结起来，似乎“浪不起来了”。</p><h3 id="锻炼"><a href="#锻炼" class="headerlink" title="锻炼"></a>锻炼</h3><p>跑步，马拉松正规的比赛没参加几场。体质完全比不了1年前的自己，体重还涨了几斤。想了解部分详情可移步<a href="http://alanzhang.me/2018/05/14/%E6%8B%86%E9%AA%A8%E4%B9%8B%E6%B2%99%E5%9F%A0DNF/#more">拆骨之沙埠DNF</a></p><h3 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h3><p>今年给我感触最大的就是，整个朋友圈炸锅似的。集体爆“红本”，结婚的好多。我自己都做了3次伴郎，参加4次婚礼。在此，祝愿结婚的2019生个可爱的小宝宝。</p><p>今年添置了一个代步座驾，算是今年最大投入吧，渐渐地成为“老司机”。</p><p>家人一切安康，小外甥上小学了。昨天还视频，看到了自己小时候的照片，时间过的好快。</p><h2 id="技能"><a href="#技能" class="headerlink" title="技能"></a>技能</h2><h3 id="公众号"><a href="#公众号" class="headerlink" title="公众号"></a>公众号</h3><p>技能好像，也没什么技能可谈。持续沉淀，持续更新公众号。2018更新17篇，平均一月一更。还算说的过去，平日里也在做着总结梳理。公众号涨粉好慢啊，说明自己还没有高质量产出。也没做好引流。有时候，偶尔会去关注公众号的关注用户，看到取消人数增长。也是警醒自己，是不是该产出了？</p><h3 id="github"><a href="#github" class="headerlink" title="github"></a>github</h3><p>更多地使用github管理自己。比如：读书笔记，blog图床，开源代码学习总结等，都会放在git上去。过往1年，新增4个仓库，159次commit。参与开源社区讨论，主要是datax相关的，之前做过一段时间数据交换的开发。<br><img src="https://github.com/alanzhang211/blog-image/raw/master/2018/12/WechatIMG127.png" alt="commit"></p><h3 id="读书"><a href="#读书" class="headerlink" title="读书"></a>读书</h3><p>买了一些实体书，有些还没来的及细看。注重读书笔记的产出，和思维导图。</p><h3 id="其他-1"><a href="#其他-1" class="headerlink" title="其他"></a>其他</h3><p>注重自己的对垂直领域知识的深入，从事大数据，对数据生态环境有了更全面的理解。这里，也源于自己工作的调整。新的环境，给予了更多的挑战。同样，自己也失去了一些自由时间。这也是前面生活中，出游折扣的原因。</p><p>知识付费服务的学习，买了<strong>gitchat</strong>和<strong>极客时间</strong>的专栏。有些专栏需要反复去看。对自己这一年来的影响还是很大的。</p><h2 id="工作"><a href="#工作" class="headerlink" title="工作"></a>工作</h2><p>上半年，工作环境不是很理想，内部调整频繁。2018整体互联网环境遇“冷”，特别是下半年互金企业的集体“爆雷”。再到年末的企业缩招，整个环境不是很好。</p><p>下半年，工作时间调整。10月份之后，一般是朝10晚9的节奏在公司。不过，学到的东西挺多的。怎么说呢，还算年轻吧，多学点。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>2018整体没有什么出彩的地方。如果要用一个词来形容，就用“中庸”吧。</p><h1 id="展望2019"><a href="#展望2019" class="headerlink" title="展望2019"></a>展望2019</h1><ul><li>公众号继续更新，开专栏。</li><li>付费知识服务阅读，读书笔记等。</li><li>其他技能培养（游泳，做饭，音乐，语言等）。</li><li>健康方面，加强锻炼，室内训练。</li><li>出游的话，还是保持原状。在空余的时间多出去走走，暂定：一次长距离旅行（出国最佳）。</li><li>个人情感提上议题（年龄不小了）。</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h1&gt;&lt;p&gt;&lt;img src=&quot;https://github.com/alanzhang211/blog-image/raw/master/2018/12/WechatIMG128.jpeg&quot; alt&gt;&lt;/p&gt;
&lt;p&gt;又是一年一度的总结大会，朋友圈各种flag。有诙谐幽默的，有简单扼要的，有朴实无华的，等等。截取部分拼了个flag墙&lt;br&gt;&lt;img src=&quot;https://github.com/alanzhang211/blog-image/raw/master/2018/12/WechatIMG126.jpeg&quot; alt=&quot;flag墙&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="总结" scheme="http://alanzhang.me/categories/%E6%80%BB%E7%BB%93/"/>
    
    
      <category term="总结" scheme="http://alanzhang.me/tags/%E6%80%BB%E7%BB%93/"/>
    
      <category term="2018" scheme="http://alanzhang.me/tags/2018/"/>
    
  </entry>
  
  <entry>
    <title>小憩一篇</title>
    <link href="http://alanzhang.me/2018/12/23/%E5%B0%8F%E6%86%A9%E4%B8%80%E7%AF%87/"/>
    <id>http://alanzhang.me/2018/12/23/小憩一篇/</id>
    <published>2018-12-23T11:45:38.000Z</published>
    <updated>2019-02-26T15:14:20.403Z</updated>
    
    <content type="html"><![CDATA[<h1 id="序"><a href="#序" class="headerlink" title="序"></a>序</h1><p>转眼，要到2019了。下午平躺在床上，总感觉少了些什么。工作中几个重要里程碑也算告一段落。这一个多月以来，略感疲惫。看书也断断续续，读书计划放缓。静下心来，是时候梳理下思路了。</p><a id="more"></a><h1 id="工作"><a href="#工作" class="headerlink" title="工作"></a>工作</h1><p>十一月份以来，慢慢地开始主导一些工作。定下来的里程碑事件，目前来看也算是如愿运行。从事大数据相关工作，也是职业生涯的转折。目前来看，水真的太深太深。所经历的领域，从最初的大数据分析，到后面的元数据治理，离线分析，然后是数据交换等，到目前的实时计算。一路走来，感受到了大数据平台的诸多组件。所设计的技术和知识域息息相关。</p><p>这一个多月，主要工作核心放在表存储治理和实时集群优化上。</p><h2 id="存储治理"><a href="#存储治理" class="headerlink" title="存储治理"></a>存储治理</h2><p>简单就是对数据的空间管理，优化存储。这里就会涉及到表生命周期的概念。力求用最少的存储成本，满足最大的业务需求。</p><p>一期，主要针对公司现有表空间进行归类梳理，对于僵尸表（近30天未访问），不更新表（近30天无增删操作），过期表（生命周期过期）。</p><p>其中过期表是此次治理的对象，对于不同层的数据表，给予不同的生命周期和移除策略。快到期进行过期通知，到期后自动将数据文件移到冷盘，进行归档。</p><p>目前，已经实现对整个公司的过期表管理，功能上线，也算是一个里程碑事件。</p><h2 id="实时集群优化"><a href="#实时集群优化" class="headerlink" title="实时集群优化"></a>实时集群优化</h2><p>这个事件，来源于对实时任务的管理。公司现状是离线任务和实时任务跑在同一个yarn集群上。为了缓解离线集群的压力，优化集群治理。将常驻的实时任务抛离出来，放在实时集群中。</p><p>那么，所需要的工作就是对现有离线集群上的任务进行迁移。以flink任务为主，也会有一些spark streaming。</p><p>目前，实时开发平台满足分集群提交的能力。历史的flink任务也慢慢地在向实时集群迁移。也算是一个里程碑事件。</p><h1 id="生活"><a href="#生活" class="headerlink" title="生活"></a>生活</h1><p>感觉生活幸福指数有点底，周末也不想参加活动。运动也少了很多。偶尔会去山上转一圈，结果计划的绕西湖群山“大圈”；结果折半，绕了个小圈回来了。</p><p>看书，买了Kindle的年度会员。下下来的几本书，也是进度缓慢。</p><p>计划春节出游，目前还没着手规划。也是一拖再拖，好担心又夭折啊。距离春节还有一个多月，看来是要着手规划了。</p><p>做饭，呃呃呃，噩梦啊。双十一买的灶具啥的还在柜子里放着，“落了一层灰”。嗯，接下来的工作节奏相对缓慢一些，可以去“开灶”了。</p><h1 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h1><p>“情感生活”：暂无；跑步比赛：暂无。</p><p>好了，好了。锅里的饭好了，不写了，留着元旦总结我的2018吧。</p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;序&quot;&gt;&lt;a href=&quot;#序&quot; class=&quot;headerlink&quot; title=&quot;序&quot;&gt;&lt;/a&gt;序&lt;/h1&gt;&lt;p&gt;转眼，要到2019了。下午平躺在床上，总感觉少了些什么。工作中几个重要里程碑也算告一段落。这一个多月以来，略感疲惫。看书也断断续续，读书计划放缓。静下心来，是时候梳理下思路了。&lt;/p&gt;
    
    </summary>
    
      <category term="杂谈" scheme="http://alanzhang.me/categories/%E6%9D%82%E8%B0%88/"/>
    
    
      <category term="2018" scheme="http://alanzhang.me/tags/2018/"/>
    
      <category term="杂谈" scheme="http://alanzhang.me/tags/%E6%9D%82%E8%B0%88/"/>
    
  </entry>
  
  <entry>
    <title>十月书单总结</title>
    <link href="http://alanzhang.me/2018/11/04/%E5%8D%81%E6%9C%88%E4%B9%A6%E5%8D%95%E6%80%BB%E7%BB%93/"/>
    <id>http://alanzhang.me/2018/11/04/十月书单总结/</id>
    <published>2018-11-04T10:03:22.000Z</published>
    <updated>2019-02-26T15:14:20.399Z</updated>
    
    <content type="html"><![CDATA[<p>十一假期回来之后，就决定看书，每月给出书单。也算是自己给自己立的一个flag吧。</p><p>重新拾起了封存多年的kindle；电脑，手机也下载了kindle软件。</p><a id="more"></a><h4 id="软技能-代码之外的生存指南"><a href="#软技能-代码之外的生存指南" class="headerlink" title="软技能-代码之外的生存指南"></a>软技能-代码之外的生存指南</h4><p><img src="https://github.com/alanzhang211/blog-image/raw/master/2018/11/%E4%BB%A3%E7%A0%81%E4%B9%8B%E5%A4%96%E7%9A%84%E7%94%9F%E5%AD%98%E6%8C%87%E5%8D%97.jpg" alt="代码之外的生存指南"></p><p><strong>书评</strong></p><p><img src="https://github.com/alanzhang211/blog-image/raw/master/2018/11/%E4%B9%A6%E5%BA%8F.png" alt="书序"></p><p>算是一本行动指导书籍吧，全书分7章。整本书的逻辑比较清晰，也比较符合大多数人的思维和职场演变。从求职就业，到职业发展，再到后期职业规划和身心的管理。不同时间段需要考虑的问题也都罗列了一些。</p><p>各个章节也相对独立，读者可以根据需要，跳过某些章节，直接看关心的部分。比如：有需要换工作的，可以直接看<strong>第五章-理财</strong>中的<strong>怎么进行薪资谈判</strong>。从我本人出发，也是踩过这方面的坑，也深有感触。</p><p>全文以一个软件工程师为背景，不过有些还是适用于各类人群的。大家不妨挑几个章节看看。</p><h4 id="HBase权威指南"><a href="#HBase权威指南" class="headerlink" title="HBase权威指南"></a>HBase权威指南</h4><p><img src="https://github.com/alanzhang211/blog-image/raw/master/2018/11/HBase%E6%9D%83%E5%A8%81%E6%8C%87%E5%8D%97.jpg" alt="HBase权威指南"></p><p>这边书以前就看过，当时对HBase这种列式存储很好奇，也是快速阅读了全书。缺少实际项目实战，慢慢地也开始淡忘。最近在做数据同步相关工作，设计到HBase相关的。于是，又细看了一边。</p><p><strong>书评</strong></p><p>本书整体脉络清晰，而且附有相关代码。很方便进行实际操作验证。并不是什么源码解读类书籍，所以看起来还算舒服。不会那么枯燥，也解决了工作中的一些疑惑。</p><h4 id="Flink基础教程"><a href="#Flink基础教程" class="headerlink" title="Flink基础教程"></a>Flink基础教程</h4><p><img src="https://github.com/alanzhang211/blog-image/raw/master/2018/11/Flink%E5%9F%BA%E7%A1%80%E6%95%99%E7%A8%8B.jpg" alt="Flink基础教程"></p><p>看这本书也是来源于工作需求，公司的流平台建设基于Flink，以及自己也想对实时计算这方面有深入的了解。于是，就开始研究起来。</p><p><strong>书评</strong></p><p>一本介绍Flink原理的书籍。介于目前国内中文相关的书籍比较少。这本作为入门的书籍还是不错的。篇幅比较短，看着看着给人意犹未尽的感觉，像一本科普类的小手册。</p><p>这里推荐Flink中国社区：<a href="https://flink-china.org/" target="_blank" rel="noopener">https://flink-china.org/</a></p><p><strong>以上就是十月份核心看的一些书籍和研究的东西，后续会做详细介绍，敬请期待。</strong></p><hr><p>读书只是开始，实践出真知。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;十一假期回来之后，就决定看书，每月给出书单。也算是自己给自己立的一个flag吧。&lt;/p&gt;
&lt;p&gt;重新拾起了封存多年的kindle；电脑，手机也下载了kindle软件。&lt;/p&gt;
    
    </summary>
    
      <category term="总结" scheme="http://alanzhang.me/categories/%E6%80%BB%E7%BB%93/"/>
    
    
      <category term="2018" scheme="http://alanzhang.me/tags/2018/"/>
    
      <category term="书单" scheme="http://alanzhang.me/tags/%E4%B9%A6%E5%8D%95/"/>
    
  </entry>
  
  <entry>
    <title>王德发，我的图挂了</title>
    <link href="http://alanzhang.me/2018/11/02/%E7%8E%8B%E5%BE%B7%E5%8F%91%EF%BC%8C%E6%88%91%E7%9A%84%E5%9B%BE%E6%8C%82%E4%BA%86/"/>
    <id>http://alanzhang.me/2018/11/02/王德发，我的图挂了/</id>
    <published>2018-11-02T12:15:06.000Z</published>
    <updated>2019-02-26T15:14:20.410Z</updated>
    
    <content type="html"><![CDATA[<p>一天早上，访问自己的Blog<a href="http://alanzhang.me/">悟-心与心的交互</a>。发现blog的配图没了，全没了。</p><a id="more"></a><h3 id="事故说明"><a href="#事故说明" class="headerlink" title="事故说明"></a>事故说明</h3><p>于是乎，看了看图片url，直接404啦。原来，借助七牛云的免费空间，使用的测试域名被回收。然后，然后去七牛云看了一眼，默认域名空了！！！</p><p><img src="https://github.com/alanzhang211/blog-image/raw/master/2018/11/domian.png" alt="默认域名"></p><p>接着想去备份下来，发现下载不下来。。。怎么办，怎么办？</p><p>接着，只能寻求客服，提工单。然后，反馈之前通知过测试域名回收相关事宜。结果，自己没有注意导致这次事故发生。</p><p><img src="https://github.com/alanzhang211/blog-image/raw/master/2018/11/youjian.png" alt="邮件"></p><p>只能找弥补措施，然后通过七牛的公开<code>qshell</code> api服务。需要将原有（域名失效）空间，迁移到新的空间中，然后在使用<code>qdownload</code> 指令将图片批量下载下来。<strong>这块还是需要有一些编程基础的人才能理解。也希望七牛云的团队，能够优化产品。</strong></p><h3 id="图床搬家啦，还是Github稳妥"><a href="#图床搬家啦，还是Github稳妥" class="headerlink" title="图床搬家啦，还是Github稳妥"></a>图床搬家啦，还是Github稳妥</h3><p>然后，依据下载说明。将原来的图库下载下来。</p><ol><li>配置命令</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">//列出全部文件信息，写入list.txt中</span><br><span class="line">qshell listbucket hexo-blog-image list.txt</span><br><span class="line">//用awk获取list结果的第一列</span><br><span class="line">cat list.txt | awk &apos;&#123;print $1&#125;&apos; &gt;list_final.txt</span><br><span class="line">//复制到新bucket的文件和原bucket文件名一致</span><br><span class="line">qshell batchcopy hexo-blog-image copy list_final.txt</span><br></pre></td></tr></table></figure><ol start="2"><li><p>安装qshell<br><img src="https://github.com/alanzhang211/blog-image/raw/master/2018/11/1.png" alt="qshell"><br>这里需要通过密钥登录验证。</p></li><li><p>创建新的工作空间</p></li></ol><p><img src="https://github.com/alanzhang211/blog-image/raw/master/2018/11/bucket.png" alt="新的工作空间"></p><p>发现，分配了新的测试域名。</p><ol start="4"><li>下载<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">//下载</span><br><span class="line">qshell qdownload download.json</span><br></pre></td></tr></table></figure></li></ol><p><code>download.json</code>是下载相关参数。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    &quot;dest_dir&quot;   :   &quot;/Users/alanzhang/alan/dev/qshell&quot;,</span><br><span class="line">    &quot;bucket&quot;     :   &quot;copy&quot;,</span><br><span class="line">    &quot;prefix&quot;     :   &quot;&quot;,</span><br><span class="line">    &quot;suffixes&quot;   :   &quot;&quot;,</span><br><span class="line">    &quot;cdn_domain&quot; :   &quot;phgxaazny.bkt.clouddn.com&quot;, //分配的新域名</span><br><span class="line">    &quot;log_file&quot;   :   &quot;download.log&quot;,</span><br><span class="line">    &quot;log_level&quot;  :   &quot;info&quot;,</span><br><span class="line">    &quot;log_rotate&quot; :   1,</span><br><span class="line">    &quot;log_stdout&quot; :   false</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img src="https://github.com/alanzhang211/blog-image/raw/master/2018/11/success.png" alt="下载成功"></p><p><img src="https://github.com/alanzhang211/blog-image/raw/master/2018/11/2.png" alt="下载指令"></p><ol start="4"><li>上传github。</li></ol><ol start="5"><li>调整blog图片url。</li></ol><p><em>注意</em><br>需要将git的路径中的<code>blob</code>改为<code>raw</code>，否则，无法现实。</p><p>如：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">https://github.com/alanzhang211/blog-image/blob/master/2018/11/domian.png</span><br><span class="line">改为：</span><br><span class="line">https://github.com/alanzhang211/blog-image/raw/master/2018/11/domian.png</span><br></pre></td></tr></table></figure></p><p>至此，图片搬家完毕。</p><hr><p><em>小贴士</em></p><p>发现，图片迁移到新空间吼，图片显现了。所以，也可以在测试域名回收之前（30天），将图片迁移到新的空间。不过，挺难受的。不知道后面七牛还会有什么变更（比如：限流，收费等）。所以，省事点还是迁移到Github上去哦。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;一天早上，访问自己的Blog&lt;a href=&quot;http://alanzhang.me/&quot;&gt;悟-心与心的交互&lt;/a&gt;。发现blog的配图没了，全没了。&lt;/p&gt;
    
    </summary>
    
      <category term="杂谈" scheme="http://alanzhang.me/categories/%E6%9D%82%E8%B0%88/"/>
    
    
      <category term="2018" scheme="http://alanzhang.me/tags/2018/"/>
    
      <category term="图床" scheme="http://alanzhang.me/tags/%E5%9B%BE%E5%BA%8A/"/>
    
      <category term="七牛云" scheme="http://alanzhang.me/tags/%E4%B8%83%E7%89%9B%E4%BA%91/"/>
    
  </entry>
  
  <entry>
    <title>DataX二次开发小记</title>
    <link href="http://alanzhang.me/2018/10/17/DataX%E4%BA%8C%E6%AC%A1%E5%BC%80%E5%8F%91%E5%B0%8F%E8%AE%B0/"/>
    <id>http://alanzhang.me/2018/10/17/DataX二次开发小记/</id>
    <published>2018-10-17T15:17:34.000Z</published>
    <updated>2019-02-26T15:14:20.375Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>本文为个人理解，如有不对之处，欢迎指正。</p></blockquote><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>之前，工作中使用datax作为数据交换组件。也简单的介绍了下datax和源码的基本导读。具体参见<a href="http://alanzhang.me/2018/04/14/DataX%E5%88%9D%E6%8E%A2/#more">DataX初探</a>。数据开发平台在数据交换同步上，从sqoop、kettle等工具，慢慢地向datax并拢。</p><h2 id="挑战"><a href="#挑战" class="headerlink" title="挑战"></a>挑战</h2><p>datax的扩展性很好，插件式安装配置。在实际使用中，往往针对实际的场景需要定制自己的读或写插件。关于如何编写插件，datax官网上也做了阐述，这里就不在赘述。详细参见：<a href="https://github.com/alibaba/DataX/blob/master/dataxPluginDev.md" target="_blank" rel="noopener">datax插件开发</a>。</p><a id="more"></a><h2 id="目标"><a href="#目标" class="headerlink" title="目标"></a>目标</h2><p>拿项目中的一个点需求：<strong>实现mysql的增量数据同步到hive</strong> 来阐插件开发过程。</p><h2 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h2><ol><li>数据变更来源：mysql变更，通过收集binlog日志进行处理，同步到kafka中。</li><li>目标数据源：hive增量分区表，通过Hbase作为中间表处理数据变更，hive建立外部表与之关联。</li></ol><p><img src="https://github.com/alanzhang211/learning-note/blob/master/img/mysql-hive.png" alt="数据流走向"></p><h3 id="插件定制"><a href="#插件定制" class="headerlink" title="插件定制"></a>插件定制</h3><ol><li>开发从kafka读插件。</li><li>开发kafka到hbase到写插件。</li><li>定制hbase读插件。</li><li>开发hive写插件。</li></ol><hr><h2 id="为什么？见下文"><a href="#为什么？见下文" class="headerlink" title="为什么？见下文"></a>为什么？见下文</h2><h3 id="插件说明"><a href="#插件说明" class="headerlink" title="插件说明"></a>插件说明</h3><h4 id="kafka读插件"><a href="#kafka读插件" class="headerlink" title="kafka读插件"></a>kafka读插件</h4><p>由于mysql的binlog会写入到kafka中，所以数据来源需要增加一个可以从kafka中读取的插件<code>kafkareader</code>。</p><p><strong>插件json定义</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;name&quot;: &quot;kafkareader&quot;,</span><br><span class="line">  &quot;parameter&quot;: &#123;</span><br><span class="line">    &quot;bootstrapServers&quot;: &quot;&quot;,</span><br><span class="line">    &quot;topic&quot;: &quot;&quot;,</span><br><span class="line">    &quot;groupId&quot;: &quot;&quot;,</span><br><span class="line">    &quot;decoder&quot;: &quot;text&quot;,</span><br><span class="line">    &quot;properties&quot;: &#123;&#125;,</span><br><span class="line">    &quot;pollTimeoutMS&quot;: 100,</span><br><span class="line">    &quot;partitionInitSeekTo&quot;: &quot;begin&quot;,</span><br><span class="line">    &quot;startOffsets&quot;: &#123;</span><br><span class="line">      &quot;0&quot;: 0,</span><br><span class="line">      &quot;1&quot;: 0</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;endOffsets&quot;: &#123;</span><br><span class="line">      &quot;0&quot;: 0,</span><br><span class="line">      &quot;1&quot;: 0</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h4 id="kafka写hbase插件"><a href="#kafka写hbase插件" class="headerlink" title="kafka写hbase插件"></a>kafka写hbase插件</h4><p>由于数据格式定制化，从公司的kafka中读取pb序列化的数据。需要解析数据加工处理。因此，在写插件中<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">public void startWriter(RecordReceiver lineReceiver)</span><br></pre></td></tr></table></figure></p><p>方法中，读取记录处理过程<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">convertRecordToPut(Record record)</span><br></pre></td></tr></table></figure></p><p>进行了定制处理。</p><h4 id="hbase读插件"><a href="#hbase读插件" class="headerlink" title="hbase读插件"></a>hbase读插件</h4><p>针对分库分表的情况，从kafka读取出来的消息存储与hbase中， <code>rowkey</code>的格式为<code>db.table.pk</code>。所以同步同一张mysql表，hbase的rowkey可能会出现多组。如果是每天同步，可能还会落到不同的表中。这就需要hbase读插件支持多组table，多组rowkey处理。</p><p><strong>原始插件json格式</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    &quot;name&quot;: &quot;hbase11xwriter&quot;,</span><br><span class="line">    &quot;parameter&quot;: &#123;</span><br><span class="line">        &quot;hbaseConfig&quot;: &#123;</span><br><span class="line">            &quot;hbase.rootdir&quot;: &quot;&quot;,</span><br><span class="line">            &quot;hbase.cluster.distributed&quot;: &quot;&quot;,</span><br><span class="line">            &quot;hbase.zookeeper.quorum&quot;: &quot;&quot;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;table&quot;: &quot;&quot;,</span><br><span class="line">        &quot;mode&quot;: &quot;&quot;,</span><br><span class="line">        &quot;rowkeyColumn&quot;: [</span><br><span class="line">        ],</span><br><span class="line">        &quot;column&quot;: [</span><br><span class="line">        ],</span><br><span class="line">        &quot;versionColumn&quot;:&#123;</span><br><span class="line">            &quot;index&quot;: &quot;&quot;,</span><br><span class="line">            &quot;value&quot;:&quot;&quot;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;encoding&quot;: &quot;&quot;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>定制版插件json定制</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    &quot;name&quot;: &quot;hbase11reader&quot;,</span><br><span class="line">    &quot;parameter&quot;: &#123;</span><br><span class="line">        &quot;hbaseConfig&quot;: &#123;&#125;,</span><br><span class="line">        &quot;tableConfig&quot;: [&#123;</span><br><span class="line">                &quot;table&quot;: &quot;&quot;,</span><br><span class="line">                &quot;range&quot;: [&#123;</span><br><span class="line">                        &quot;startRowkey&quot;: &quot;&quot;,</span><br><span class="line">                        &quot;endRowkey&quot;: &quot;&quot;</span><br><span class="line">                    &#125;,</span><br><span class="line">                    &#123;</span><br><span class="line">                        &quot;startRowkey&quot;: &quot;&quot;,</span><br><span class="line">                        &quot;endRowkey&quot;: &quot;&quot;</span><br><span class="line">                    &#125;]</span><br><span class="line">        &#125;],</span><br><span class="line">        &quot;date&quot;:&quot;&quot;,</span><br><span class="line">        &quot;encoding&quot;: &quot;&quot;,</span><br><span class="line">        &quot;mode&quot;: &quot;&quot;,</span><br><span class="line">        &quot;column&quot;: [],</span><br><span class="line">        &quot;isBinaryRowkey&quot;: true</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>对比，主要的变化就是从单表<code>table</code>变为多表<code>tableConfig</code>数组配置项。</p><p>后续，讲以此插件的定义过程，讲解插件开发思路。</p><h4 id="hive写插件"><a href="#hive写插件" class="headerlink" title="hive写插件"></a>hive写插件</h4><p>由于要支持hive分区处理。所以，原生的datax实现hive的读、写，底层原理是通过直接操作hdfs的方式处理的（使用hdfsreader、hdfswriter）。</p><p>这样，就hive表的分区信息一无所知。因此，这里采用<code>HCatalog</code>作为操作hive数据的接口。关于<code>HCatalog</code>简单说明：</p><blockquote><p>HCatalog屏蔽了底层数据存储的位置格式等信息，为上层计算处理流程提供统一的、共享的metadata。并且将数据以表的形式呈现给用户（如Pig,MR,Hive,Streaming..），用户只需提供表名就可以访问底层数据，并不需要关心底层数据的位置，模式等信息。</p></blockquote><p><strong>插件josn定义</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;name&quot;: &quot;hivewriter&quot;,</span><br><span class="line">  &quot;parameter&quot;: &#123;</span><br><span class="line">    &quot;database&quot;: &quot;&quot;,</span><br><span class="line">    &quot;table&quot;: &quot;&quot;,</span><br><span class="line">    &quot;partition&quot;: &quot;&quot;,</span><br><span class="line">    &quot;hadoopConf&quot;: [</span><br><span class="line">      &quot;&quot;</span><br><span class="line">    ],</span><br><span class="line">    &quot;kerberosPrincipal&quot;: &quot;&quot;,</span><br><span class="line">    &quot;kerberosKeytab&quot;: &quot;&quot;,</span><br><span class="line">    &quot;batchSize&quot;: 10000,</span><br><span class="line">    &quot;overwrite&quot;: false</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><hr><h2 id="进入主题"><a href="#进入主题" class="headerlink" title="进入主题"></a>进入主题</h2><h2 id="插件开发过程"><a href="#插件开发过程" class="headerlink" title="插件开发过程"></a>插件开发过程</h2><p>针对上述定制插件中的hbasereader进行讲述。针对读写插件，总结下来就是<code>一个配置，2个对象</code>。</p><p><img src="https://github.com/alanzhang211/learning-note/blob/master/img/WechatIMG106.png" alt="读写组件"></p><h3 id="一个配置"><a href="#一个配置" class="headerlink" title="一个配置"></a>一个配置</h3><p>就是插件的json配置，最终在代码层次上会抽象为<code>Configuration</code>对象。这是任务执行的依据。</p><h3 id="2个对象"><a href="#2个对象" class="headerlink" title="2个对象"></a>2个对象</h3><ol><li>job：作业信息载体。</li><li>task：作业执行载体。</li></ol><h3 id="核心方法"><a href="#核心方法" class="headerlink" title="核心方法"></a>核心方法</h3><h4 id="Job-split"><a href="#Job-split" class="headerlink" title="Job.split"></a>Job.split</h4><p>这是一个任务切分处理逻辑，最终会讲总的json，拆分成最小的执行单元配置传递给task。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">@Override</span><br><span class="line">public List&lt;Configuration&gt; split(int adviceNumber) &#123;</span><br><span class="line">    return null;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>针对此定制插件，就是通过split方法，将<code>tableConfig</code>拆分，退化为最原始插件的配置形式（单个table，单组rowkey）。最终，针对task而言，执行配置<code>split</code>处理逻辑也不变。</p><h4 id="Task-startRead"><a href="#Task-startRead" class="headerlink" title="Task.startRead"></a>Task.startRead</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">@Override</span><br><span class="line">    public void startRead(RecordSender recordSender) &#123;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这个是读记录过程，也是读插件的核心。经过Job的split处理后，对于task的Configuration处理过程也是和原始的一样。这里要做的就是：<strong>是否需要对读记录进行二次处理加工</strong>。</p><h3 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h3><p>之后，就会将task提交个任务执行容器框架去处理。另外，如果需要统计处理，也可以在<code>Task.startRead</code>中调用<code>TaskPluginCollector</code>任务收集器进行统计收集。</p><h2 id="结语"><a href="#结语" class="headerlink" title="结语"></a>结语</h2><p>此次开发定制，深入到插件层，对插件的数据走向有了深入了解。同时也对很多组件（kafka、hbase、hive等）有了了解。</p><hr><p><em>实践出真知</em></p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;本文为个人理解，如有不对之处，欢迎指正。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;之前，工作中使用datax作为数据交换组件。也简单的介绍了下datax和源码的基本导读。具体参见&lt;a href=&quot;http://alanzhang.me/2018/04/14/DataX%E5%88%9D%E6%8E%A2/#more&quot;&gt;DataX初探&lt;/a&gt;。数据开发平台在数据交换同步上，从sqoop、kettle等工具，慢慢地向datax并拢。&lt;/p&gt;
&lt;h2 id=&quot;挑战&quot;&gt;&lt;a href=&quot;#挑战&quot; class=&quot;headerlink&quot; title=&quot;挑战&quot;&gt;&lt;/a&gt;挑战&lt;/h2&gt;&lt;p&gt;datax的扩展性很好，插件式安装配置。在实际使用中，往往针对实际的场景需要定制自己的读或写插件。关于如何编写插件，datax官网上也做了阐述，这里就不在赘述。详细参见：&lt;a href=&quot;https://github.com/alibaba/DataX/blob/master/dataxPluginDev.md&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;datax插件开发&lt;/a&gt;。&lt;/p&gt;
    
    </summary>
    
      <category term="大数据" scheme="http://alanzhang.me/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="2018" scheme="http://alanzhang.me/tags/2018/"/>
    
      <category term="数据同步" scheme="http://alanzhang.me/tags/%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5/"/>
    
      <category term="DataX" scheme="http://alanzhang.me/tags/DataX/"/>
    
      <category term="大数据" scheme="http://alanzhang.me/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
  </entry>
  
  <entry>
    <title>十一哈巴雪山-丽江行</title>
    <link href="http://alanzhang.me/2018/10/07/%E5%8D%81%E4%B8%80%E5%93%88%E5%B7%B4%E9%9B%AA%E5%B1%B1-%E4%B8%BD%E6%B1%9F%E8%A1%8C/"/>
    <id>http://alanzhang.me/2018/10/07/十一哈巴雪山-丽江行/</id>
    <published>2018-10-07T06:28:23.000Z</published>
    <updated>2019-02-26T15:14:20.398Z</updated>
    
    <content type="html"><![CDATA[<h1 id="序"><a href="#序" class="headerlink" title="序"></a>序</h1><p>“读万卷书，不如行万里路。”这句话，时常被人挂在嘴边。渐渐地便对这就话欣然接受。旅行确实是历练人地最好方式之一。</p><p>喜欢一个人背着包，远离生活、工作中地种种羁绊。时间久了，好像也就那么回事。</p><p>今年的国庆，由于前期工作调整，没有好好规划。本来年初两个选择</p><ol><li>出国学习潜水，一直想了解深海的气世界。</li><li>去日本见基友，顺便了解下日本的ACG文化。</li></ol><p>就在假期前一个星期，才决定，去远足。于是，在一个户外群里看到了哈巴雪山的行程。想了想，这也不错呀，雪是见过不少，雪山确实没怎么上过。于是做了决定，但是仔细看了行程单，29号飞丽江。对于没有假期的我，有些犹豫了。就在出发当天下午开例会的时候，还在想要不要去。不过现在想来还是值得的，因为这次行程感受颇深，也经历了很多。自然，人性的碰撞。</p><a id="more"></a><h1 id="自然篇"><a href="#自然篇" class="headerlink" title="自然篇"></a>自然篇</h1><p>感受自然，接触自然。这是一篇不带有人性情感的阐述。</p><h2 id="D1-丽江-哈巴村"><a href="#D1-丽江-哈巴村" class="headerlink" title="D1-丽江-哈巴村"></a>D1-丽江-哈巴村</h2><p><strong>时间：9.30</strong></p><p><strong>地点：丽江，哈巴村</strong></p><h3 id="虎跳峡"><a href="#虎跳峡" class="headerlink" title="虎跳峡"></a>虎跳峡</h3><p>9.29号晚上十点飞机宁波出发，次日2点到达丽江机场。夜宿机场附近酒店，早上出发前往哈巴村。途中经过虎跳峡景区，被湍急的金沙江气势震撼到了。</p><p><img src="https://github.com/alanzhang211/blog-image/raw/master/2018/10/%E6%88%B7%E5%A4%96/%E8%99%8E%E8%B7%B3%E5%B3%A1.png" alt="虎跳峡"></p><p><img src="https://github.com/alanzhang211/blog-image/raw/master/2018/10/%E6%88%B7%E5%A4%96/%E8%99%8E%E8%B7%B3%E5%B3%A1%E6%B5%B7%E6%8B%94.png" alt="虎跳峡海拔"></p><p><img src="https://github.com/alanzhang211/blog-image/raw/master/2018/10/%E6%88%B7%E5%A4%96/%E5%89%8D%E5%BE%80%E5%93%88%E5%B7%B4%E6%9D%91.png" alt="前往哈巴村"></p><p>停留了大概1小时左右，随行9人匆匆赶往下一站-哈巴村。这也是此行登顶哈巴雪山的必经之地。</p><h3 id="哈巴村"><a href="#哈巴村" class="headerlink" title="哈巴村"></a>哈巴村</h3><p>哈巴村位于哈巴雪山西面山脚下，是一个以纳西族为主的村落，她把登山人和哈巴雪山紧密地联系在一起，是一个登山客云集的“沙木尼镇”。</p><p>是一个淳朴的小村落，问了当地人，这里有10多个少数名族，其中，汉族有100多户。在这里，以旅游业（依傍着哈巴雪山）为主。每户种植、养殖多数都是自给自足。这里海拔大概2k8左右，紫外线还是很强烈的。到了哈巴村已经快下午5点了，宁静的小村落，没有过多的时间去打量她，只能利用黄昏前的片刻时间去了解。</p><p><img src="https://github.com/alanzhang211/blog-image/raw/master/2018/10/%E6%88%B7%E5%A4%96/%E5%93%88%E5%B7%B4%E6%9D%91.png" alt="哈巴村"></p><p>村里的植被很多，平日里在城市很难见到。印象比较深刻的就是那个甘甜的山梨啦，真的又脆又甜。本想离开哈巴村的时候买点回去。无奈次日下山后，天已经黑了。</p><p><img src="https://github.com/alanzhang211/blog-image/raw/master/2018/10/%E6%88%B7%E5%A4%96/%E5%B1%B1%E6%A2%A8.png" alt="山梨"></p><h2 id="D2（哈巴村-哈巴大本营）"><a href="#D2（哈巴村-哈巴大本营）" class="headerlink" title="D2（哈巴村-哈巴大本营）"></a>D2（哈巴村-哈巴大本营）</h2><p><strong>时间：10.1</strong></p><p><strong>地点：哈巴村，哈巴大本营</strong></p><h3 id="哈巴村上山"><a href="#哈巴村上山" class="headerlink" title="哈巴村上山"></a>哈巴村上山</h3><p>早上按计划进行，早8点坐车到山脚下。整理着装，开始向哈巴雪山大本营进发。开始步入神秘的高原森林。</p><p><img src="https://github.com/alanzhang211/blog-image/raw/master/2018/10/%E6%88%B7%E5%A4%96/%E5%8E%9F%E5%A7%8B%E6%A3%AE%E6%9E%97.png" alt="原始森林"></p><p>沿途看到一些被伐倒的树干，布满青苔。历史遗留的痕迹。“靠山吃山，靠水吃水。”以前，伐木养家也理所当然，现如今也慢慢开始转变。</p><p><img src="https://github.com/alanzhang211/blog-image/raw/master/2018/10/%E6%88%B7%E5%A4%96/%E4%BC%90%E6%9C%A8.png" alt="伐木"></p><h3 id="大本营"><a href="#大本营" class="headerlink" title="大本营"></a>大本营</h3><p>大概走了4个小时，来到了海拔4k1的哈巴雪山大本营。这是一个不大的营地。几座山屋紧密的挨着。</p><p><img src="https://github.com/alanzhang211/blog-image/raw/master/2018/10/%E6%88%B7%E5%A4%96/%E5%A4%A7%E6%9C%AC%E8%90%A5.png" alt="哈巴大本营"></p><p>这里位于雨线地带，所以，时不时都会伴有暴雨。晚上，吃了当地人精心准备的饭食后。随行人便开始准备明天用的登山装备。</p><p>计划次日3点出发，预示着这是一个不眠夜。深夜，外面风雨交加；屋内，各个都裹着被子。有人难以入睡，有人鼾声连连，有人则高反等等，形形色色，形态百样。</p><h2 id="D3（哈巴山-哈巴村）"><a href="#D3（哈巴山-哈巴村）" class="headerlink" title="D3（哈巴山-哈巴村）"></a>D3（哈巴山-哈巴村）</h2><p><strong>时间：10.2</strong></p><p><strong>地点：哈巴雪山，哈巴大本营，哈巴村</strong></p><p>随着一阵敲门声，人们从睡梦中醒来。登山向导来敲门了，也预示着，登山即将开始。</p><p>大伙儿喝了点粥，纷纷拿好背包，蓄势待发。凌晨的哈巴山很安静，雨水也停了。等着头灯就开始向上攀登。</p><p><img src="https://github.com/alanzhang211/blog-image/raw/master/2018/10/%E6%88%B7%E5%A4%96/%E6%94%80%E7%99%BB.png" alt="攀登"></p><p>登顶途中，暴雨，大雪。保暖真的很重要。狂风，绝壁，安全第一位。大概在4k7的位置，看到了雪。</p><p><img src="https://github.com/alanzhang211/blog-image/raw/master/2018/10/%E6%88%B7%E5%A4%96/%E9%80%94%E4%B8%AD.png" alt="途中"></p><p>11点多登顶，山顶能见度低，果然没有网上的好看。那种天气，一年也没有几次，真的看运气。</p><p><img src="https://github.com/alanzhang211/blog-image/raw/master/2018/10/%E6%88%B7%E5%A4%96/%E7%99%BB%E9%A1%B6.png" alt="登顶"></p><p>停留片刻，便开始下撤，大概下午3点左右到达大本营。因为当天要回丽江，于是稍作休息。就开始下撤回哈巴村。回到哈巴村，已经是下午7点，天色也渐渐暗淡下来。</p><p>顾不上洗漱整理，稍微吃了点就上车前往丽江。</p><hr><h1 id="人性篇"><a href="#人性篇" class="headerlink" title="人性篇"></a>人性篇</h1><p>这是一篇人性的交流，摆脱自然，回归人心，体会人与人之间的友情，亲情，性情……</p><h2 id="D4（丽江）"><a href="#D4（丽江）" class="headerlink" title="D4（丽江）"></a>D4（丽江）</h2><p><strong>时间：10.3</strong></p><p><strong>地点：丽江，丽江古城</strong></p><p>3号凌晨到达丽江，入住了丽江古城内的一家民宿。民宿还不错，应该说整个古城内的建筑都有格调。</p><p><img src="https://github.com/alanzhang211/blog-image/raw/master/2018/10/%E6%88%B7%E5%A4%96/%E6%B0%91%E5%AE%BF2.png" alt="民宿"></p><p>下山后，脱离尘嚣的我们再次进入闹市。在这里，需要考虑人与人之间的种种情感。待人处事，言辞举止似乎都需要去细细评味。和我同行的人中，大部分都年长于我。交流过程中，很多东西，很多处事之道不是很了解。可能也是自己圈子的缘故。有些东西我很难去体会，也不愿意去体会。可是，这就是人性，需要你去了解它。</p><p>丽江古城是一个充满神奇的地方。住进去，感觉就像进入了一个“万象城”。这一秒是这样，下一秒可能就是那样。在古城的映衬下，形形色色的人群穿梭其中。</p><p><img src="https://github.com/alanzhang211/blog-image/raw/master/2018/10/%E6%88%B7%E5%A4%96/%E8%A1%97%E9%81%93.png" alt="街道"></p><p>大概上午10点多，古城内才渐渐出现人的身影。据了解，这里的生活节奏都比较慢。古城还是蛮大的，街道纵横交错。特色饰品店，小吃店，音乐酒吧（晚上才开）等等散落于古城之中。丽江的茶文化给我感触挺深刻的。可能是随行人中很多都对茶道略知一二，而且，住的民宿也是个茶文化很深的。老板还亲自泡茶给我们喝。喝茶中，对茶也有了更深刻的理解。</p><p><img src="https://github.com/alanzhang211/blog-image/raw/master/2018/10/%E6%88%B7%E5%A4%96/%E5%96%9D%E8%8C%B6.png" alt="喝茶"></p><p>晚上，夜色降临。昏暗的路灯下，看不太清人的脸。散落于城中的酒吧也开始喧嚣起来。说起酒吧，这算是我第二次来了吧。第一次还是刚工作那会，去的一个清吧。第一次来这种热闹的音乐吧。也喝了一些第一次喝的酒。</p><p><img src="https://github.com/alanzhang211/blog-image/raw/master/2018/10/%E6%88%B7%E5%A4%96/%E9%85%92%E5%90%A7.png" alt="酒吧"></p><p>古城内，经历了很多人生中的第一次，第一次这么正规的品茶等等（此处省略若干字）。</p><h1 id="结语"><a href="#结语" class="headerlink" title="结语"></a>结语</h1><p>以一张朦胧之美结束此次十一之行，慢慢品味！</p><p><img src="https://github.com/alanzhang211/blog-image/raw/master/2018/10/%E6%88%B7%E5%A4%96/%E4%BA%BA.png" alt="人"></p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;序&quot;&gt;&lt;a href=&quot;#序&quot; class=&quot;headerlink&quot; title=&quot;序&quot;&gt;&lt;/a&gt;序&lt;/h1&gt;&lt;p&gt;“读万卷书，不如行万里路。”这句话，时常被人挂在嘴边。渐渐地便对这就话欣然接受。旅行确实是历练人地最好方式之一。&lt;/p&gt;
&lt;p&gt;喜欢一个人背着包，远离生活、工作中地种种羁绊。时间久了，好像也就那么回事。&lt;/p&gt;
&lt;p&gt;今年的国庆，由于前期工作调整，没有好好规划。本来年初两个选择&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;出国学习潜水，一直想了解深海的气世界。&lt;/li&gt;
&lt;li&gt;去日本见基友，顺便了解下日本的ACG文化。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;就在假期前一个星期，才决定，去远足。于是，在一个户外群里看到了哈巴雪山的行程。想了想，这也不错呀，雪是见过不少，雪山确实没怎么上过。于是做了决定，但是仔细看了行程单，29号飞丽江。对于没有假期的我，有些犹豫了。就在出发当天下午开例会的时候，还在想要不要去。不过现在想来还是值得的，因为这次行程感受颇深，也经历了很多。自然，人性的碰撞。&lt;/p&gt;
    
    </summary>
    
      <category term="行万里路" scheme="http://alanzhang.me/categories/%E8%A1%8C%E4%B8%87%E9%87%8C%E8%B7%AF/"/>
    
    
      <category term="2018" scheme="http://alanzhang.me/tags/2018/"/>
    
      <category term="十一" scheme="http://alanzhang.me/tags/%E5%8D%81%E4%B8%80/"/>
    
      <category term="哈巴雪山" scheme="http://alanzhang.me/tags/%E5%93%88%E5%B7%B4%E9%9B%AA%E5%B1%B1/"/>
    
      <category term="丽江" scheme="http://alanzhang.me/tags/%E4%B8%BD%E6%B1%9F/"/>
    
  </entry>
  
  <entry>
    <title>渡劫</title>
    <link href="http://alanzhang.me/2018/09/16/%E6%B8%A1%E5%8A%AB/"/>
    <id>http://alanzhang.me/2018/09/16/渡劫/</id>
    <published>2018-09-16T10:07:19.000Z</published>
    <updated>2019-02-26T15:14:20.409Z</updated>
    
    <content type="html"><![CDATA[<h3 id="题记"><a href="#题记" class="headerlink" title="题记"></a>题记</h3><p><img src="https://github.com/alanzhang211/blog-image/raw/master/2018/09/%E6%9D%82%E8%B0%88/20180916.png" alt></p><p>距上次博文更新已经好几个月了，一直没有更新。一方面，是自己在这半年时间里一直做技术沉淀（大部分属于技术总结类），所以没有同步更新到博客上。喜欢的可以移步文末个人公众号浏览。再者，开始考虑进行工作调整（7月面试，8月确定，9月入职）。目前已在新东家上班数日。适应了节奏，缓了缓，想了想，还是做一下“渡劫”后的感受。</p><a id="more"></a><h3 id="主体"><a href="#主体" class="headerlink" title="主体"></a>主体</h3><p>舒适期让人失去了危机感，前东家，公司系统成型，主要工作是维护和业务优化；为了适应市场需求，公司做了多次架构调整。在舒适区的自己变得懈怠，缺少激情。于是乎，产生了“渡劫”的想法。</p><p>7月初，整理了简历，投递到某平台。第二天就收到了面试邀请。经历几次面试过程，拿到一些offer，有交流很愉快的，也有被虐的很惨的。大数据相关背景出身，在和面试官交流中，体会到自己对这块领域的认知还是浮在上面。最终选择了一家数据相关工作，和现有的职务匹配。7月下旬，确定offer。8月提出离职，9月入职。</p><p>入职，带着小小的期待。新东家的技术架构不同于前公司，不过也是业界成熟度很高的，数据部门的产品形态相比更加细化。目前看来，数据产品是在进行新老更替。这也是一家公司从创业到上市；业务从试探，到成熟；产品也是不断在迭代适应中改变。历史的“车轮”无法带动目前庞大的“车体”，只能换“架子”。</p><p>在入职几天里。自己接触到任务，不同于之前的系统，需要你学习，需要你去熟悉新的生态，新的团队，新的工作节奏。这是一个适应期，“渡劫”开始，是劳心的。</p><p>技术学习无止尽，感受到了团队的技术底蕴。需要自己付出更多的精力去应对。前期的舒适让自己有些迷途。这么一看，正好是个棒槌敲打了自己，使得自己清醒很多。目前上下班消耗的时间太多。运动健身也慢慢从每日日程中抹去。“渡劫”开始，自己也调整了生活环境，想赢得更多的时间用于渡化自己（也不想失去自己的爱好）。博客更新也要持续进行。</p><h3 id="尾声"><a href="#尾声" class="headerlink" title="尾声"></a>尾声</h3><p><em>实迷途其未远，觉今是而昨非。</em></p>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;题记&quot;&gt;&lt;a href=&quot;#题记&quot; class=&quot;headerlink&quot; title=&quot;题记&quot;&gt;&lt;/a&gt;题记&lt;/h3&gt;&lt;p&gt;&lt;img src=&quot;https://github.com/alanzhang211/blog-image/raw/master/2018/09/%E6%9D%82%E8%B0%88/20180916.png&quot; alt&gt;&lt;/p&gt;
&lt;p&gt;距上次博文更新已经好几个月了，一直没有更新。一方面，是自己在这半年时间里一直做技术沉淀（大部分属于技术总结类），所以没有同步更新到博客上。喜欢的可以移步文末个人公众号浏览。再者，开始考虑进行工作调整（7月面试，8月确定，9月入职）。目前已在新东家上班数日。适应了节奏，缓了缓，想了想，还是做一下“渡劫”后的感受。&lt;/p&gt;
    
    </summary>
    
      <category term="生活感悟" scheme="http://alanzhang.me/categories/%E7%94%9F%E6%B4%BB%E6%84%9F%E6%82%9F/"/>
    
    
      <category term="2018" scheme="http://alanzhang.me/tags/2018/"/>
    
      <category term="感悟" scheme="http://alanzhang.me/tags/%E6%84%9F%E6%82%9F/"/>
    
  </entry>
  
  <entry>
    <title>拆骨之沙埠DNF</title>
    <link href="http://alanzhang.me/2018/05/14/%E6%8B%86%E9%AA%A8%E4%B9%8B%E6%B2%99%E5%9F%A0DNF/"/>
    <id>http://alanzhang.me/2018/05/14/拆骨之沙埠DNF/</id>
    <published>2018-05-14T14:56:41.000Z</published>
    <updated>2019-02-26T15:14:20.405Z</updated>
    
    <content type="html"><![CDATA[<p>今年越野跑的第一个DNF献给了拆骨。都说拆骨让你又爱又恨，爱：补给好；恨：关门卡的紧。<br><img src="https://github.com/alanzhang211/blog-image/raw/master//2018/05/%E6%B2%99%E5%9F%A0/%E6%B2%99%E5%9F%A0%E8%B6%8A%E9%87%8E.jpeg" alt="沙埠越野跑"></p><a id="more"></a><p>5.5号从杭州出发，去台州参加第3届沙埠越野赛。心里很期待，这是我第一次参加拆骨的赛事（哦，不对，16年作为志愿者。参加了首届“爱丽丝”杭州站）感兴趣的可以围观<a href="http://alanzhang.me/2016/10/23/first-volunteer-of-my-running-life/">first-volunteer-of-my-running-life</a>。</p><p>大概下午4点到黄岩大酒店，领取参赛包。看到了，几个熟悉的面孔，也是圈里的红人。说实话，自己对这次比赛也很忐忑。赛前，也就每天下班回来，5-10公里路跑训练。路跑和越野跑差别还是挺大的。对腿部力量要求很高，一般上坡大腿力量很重要。这次去，也是抱着完赛的心态去的。<br><img src="https://github.com/alanzhang211/blog-image/raw/master//2018/05/%E6%B2%99%E5%9F%A0/%E5%8F%82%E8%B5%9B%E5%8C%85.jpeg" alt="参赛包"></p><p>早上。全程（35km）7:30起跑，半程（20km）8点起跑。由于住在黄岩区，早上6点要乘坐接驳车去沙埠。所以，早上5点起床。算下来，睡了4-5个小时，中间醒了好几次。完全没有睡熟，起来很难受。喝了瓶八宝粥，啃了几口面包。结果证实，早饭还是要吃饱点啊。</p><p><img src="https://github.com/alanzhang211/blog-image/raw/master//2018/05/%E6%B2%99%E5%9F%A0/%E8%B5%B7%E7%BB%88%E7%82%B9.jpeg" alt="起终点"></p><p><img src="https://github.com/alanzhang211/blog-image/raw/master//2018/05/%E6%B2%99%E5%9F%A0/%E5%BC%80%E8%B7%91.jpeg" alt="起跑"></p><p>7:30全程组起跑，我也在其中。前5公里的路跑，下坡。跑起来挺嗨。过了cp1，之后，便是赛道的爬升最大的坡。<br><img src="https://github.com/alanzhang211/blog-image/raw/master//2018/05/%E6%B2%99%E5%9F%A0/cp1.jpeg" alt="cp1"></p><p><img src="https://github.com/alanzhang211/blog-image/raw/master//2018/05/%E6%B2%99%E5%9F%A0/%E7%88%AC%E5%8D%87%E5%9B%BE.jpeg" alt="爬升图"></p><p>这个坡，直接把好多人拉爆。中途遇到几个退赛的，当时自己也有点心动。当时，自己的大腿有点感觉。还是赛前没有好好练习力量，导致腿部发软。所以，到了下坡的时候，自己也不敢放开了跑，毕竟腿软，容易受伤。</p><p><img src="https://github.com/alanzhang211/blog-image/raw/master//2018/05/%E6%B2%99%E5%9F%A0/%E8%B5%9B%E9%81%93%E9%A3%8E%E5%85%891.jpeg" alt="赛道照1"></p><p><img src="https://github.com/alanzhang211/blog-image/raw/master//2018/05/%E6%B2%99%E5%9F%A0/%E8%B5%9B%E9%81%931.jpeg" alt="赛道照2"></p><p><img src="https://github.com/alanzhang211/blog-image/raw/master//2018/05/%E6%B2%99%E5%9F%A0/%E8%B5%9B%E9%81%93%E7%85%A7.jpeg" alt="赛道照3"></p><p>然后，艰难的10几公里的cp2.这是一个关门点。看看手表，关门之前通过应该没问题。当时太阳也挺厉害，肠胃也不舒服。到了卡点，看到补给点的补给真的不错。冰可乐，甜瓜，椰奶等。坐下来，慢慢吃。肠胃不舒服，加上后面的卡点时间太紧。犹豫了许久，决定退赛。</p><p><img src="https://github.com/alanzhang211/blog-image/raw/master//2018/05/%E6%B2%99%E5%9F%A0/%E8%A1%A5%E7%BB%99%E7%AB%99.jpeg" alt="补给站"></p><p><img src="https://github.com/alanzhang211/blog-image/raw/master//2018/05/%E6%B2%99%E5%9F%A0/%E8%B7%AF%E6%A0%87.jpeg" alt="路标"></p><p>之后，坐着老板娘的车回到了起终点（太湖山庄度假酒店）。稍微调整一下，吃了点午餐。看到，陆续到达终点的小伙伴。感慨这次比赛太不重视了。赛前不好好准备，希望明年再战。收复失地。</p><p>此次越野跑以DNF的交了答卷，来年再战。</p><p><img src="https://github.com/alanzhang211/blog-image/raw/master//2018/05/%E6%B2%99%E5%9F%A0/DNF.jpeg" alt="DNF"></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;今年越野跑的第一个DNF献给了拆骨。都说拆骨让你又爱又恨，爱：补给好；恨：关门卡的紧。&lt;br&gt;&lt;img src=&quot;https://github.com/alanzhang211/blog-image/raw/master//2018/05/%E6%B2%99%E5%9F%A0/%E6%B2%99%E5%9F%A0%E8%B6%8A%E9%87%8E.jpeg&quot; alt=&quot;沙埠越野跑&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="户外运动" scheme="http://alanzhang.me/categories/%E6%88%B7%E5%A4%96%E8%BF%90%E5%8A%A8/"/>
    
    
      <category term="越野" scheme="http://alanzhang.me/tags/%E8%B6%8A%E9%87%8E/"/>
    
      <category term="2018" scheme="http://alanzhang.me/tags/2018/"/>
    
  </entry>
  
  <entry>
    <title>DataX初探</title>
    <link href="http://alanzhang.me/2018/04/14/DataX%E5%88%9D%E6%8E%A2/"/>
    <id>http://alanzhang.me/2018/04/14/DataX初探/</id>
    <published>2018-04-14T15:06:21.000Z</published>
    <updated>2019-02-26T15:14:20.375Z</updated>
    
    <content type="html"><![CDATA[<h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><p>DataX 是一个异构数据源离线同步工具，致力于实现包括关系型数据库(MySQL、Oracle等)、HDFS、Hive、ODPS、HBase、FTP等各种异构数据源之间稳定高效的数据同步功能。</p><p><img src="https://github.com/alanzhang211/learning-note/raw/master/img/%E6%98%9F%E5%BD%A2%E7%8A%B6.png" alt="星形状"></p><a id="more"></a><h1 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h1><h2 id="框架"><a href="#框架" class="headerlink" title="框架"></a>框架</h2><p><img src="https://github.com/alanzhang211/learning-note/raw/master/img/%E5%8E%9F%E7%90%86.png" alt="原理"></p><p><strong>DataX本身作为离线数据同步框架，采用Framework + plugin架构构建。将数据源读取和写入抽象成为Reader/Writer插件，纳入到整个同步框架中。</strong></p><ul><li>Reader：Reader为数据采集模块，负责采集数据源的数据，将数据发送给Framework。</li><li>Writer： Writer为数据写入模块，负责不断向Framework取数据，并将数据写入到目的端。</li><li>Framework：Framework用于连接reader和writer，作为两者的数据传输通道，并处理缓冲，流控，并发，数据转换等核心技术问题。</li></ul><h2 id="Job执行"><a href="#Job执行" class="headerlink" title="Job执行"></a>Job执行</h2><p>首先，Job根据不同的分片策略，将任务分为多个任务组，每个组包含等量的子任务。然后提交给调度器，调度器启动后，执行读写逻辑线程。如下图示：</p><p><img src="https://github.com/alanzhang211/learning-note/raw/master/img/job.png" alt="job"></p><p>大体的交互流程如下示：</p><p><img src="https://github.com/alanzhang211/learning-note/raw/master/img/job-flow.png" alt="执行流程"></p><h2 id="调用方式"><a href="#调用方式" class="headerlink" title="调用方式"></a>调用方式</h2><h3 id="运行"><a href="#运行" class="headerlink" title="运行"></a>运行</h3><p>命令行调用：<br>python {DATAX_HOME}/bin/datax.py {JSON_FILE_NAME}.json</p><p>其中，’datax.py’ 是python编写的调用入口。</p><h3 id="本地debug"><a href="#本地debug" class="headerlink" title="本地debug"></a>本地debug</h3><p>Engine是DataX入口类，该类负责初始化Job或者Task的运行容器，并运行插件的Job或者Task逻辑。</p><p>com.alibaba.datax.core.Engine 的main方法。</p><p><img src="https://github.com/alanzhang211/learning-note/raw/master/img/engine-main.png" alt="engine-main"></p><h2 id="核心类介绍"><a href="#核心类介绍" class="headerlink" title="核心类介绍"></a>核心类介绍</h2><h3 id="JobContainer"><a href="#JobContainer" class="headerlink" title="JobContainer"></a>JobContainer</h3><p>jobContainer主要负责的工作全部在start()里面，包括init、prepare、split、scheduler、post以及destroy和statistics。</p><p>JobContainer的schedule首先完成的工作是把上一步reader和writer split的结果整合到具体taskGroupContainer中,同时不同的执行模式调用不同的调度策略，将所有任务调度起来。</p><p>将调度执行逻辑委派给AbstractScheduler的schedule(taskGroupConfigs)，方法中</p><p><img src="https://github.com/alanzhang211/learning-note/raw/master/img/scheduler.png" alt="scheduler"></p><h3 id="AbstractScheduler"><a href="#AbstractScheduler" class="headerlink" title="AbstractScheduler"></a>AbstractScheduler</h3><p>AbstractScheduler的子类执行任务线程，使用固定大小线程池管理taskGroup。</p><p><img src="https://github.com/alanzhang211/learning-note/raw/master/img/AbstractScheduler.png" alt="AbstractScheduler"></p><h3 id="TaskGroupContainerRunner"><a href="#TaskGroupContainerRunner" class="headerlink" title="TaskGroupContainerRunner"></a>TaskGroupContainerRunner</h3><p>TaskGroupContainerRunner的run方法，执行TaskGroupContainer的start方法。这样，一个任务组就开始在线程池中运行了。</p><p><img src="https://github.com/alanzhang211/learning-note/raw/master/img/TaskGroupContainerRunner.png" alt="TaskGroupContainerRunner"></p><h3 id="TaskExecutor"><a href="#TaskExecutor" class="headerlink" title="TaskExecutor"></a>TaskExecutor</h3><p>TaskExecutor是一个完整task的执行器，内部包含reader和writer线程。</p><h3 id="读写组件"><a href="#读写组件" class="headerlink" title="读写组件"></a>读写组件</h3><p>以mysql为例。读写组件类图如下示：</p><p><img src="https://github.com/alanzhang211/learning-note/raw/master/img/MysqlReader.png" alt="mysql-reader"></p><p><img src="https://github.com/alanzhang211/learning-note/raw/master/img/MysqlWriter.png" alt="mysql-writer"></p><p>reader和writer内部结构类似，核心内部类Job和Task。Job主要负责一系列的环境处理；Task完成了读取或写入的实现逻辑。</p><h1 id="源码"><a href="#源码" class="headerlink" title="源码"></a>源码</h1><p><em>fork了datax的源码，后续进行源码分析，增加代码注释。</em><a href="https://github.com/alanzhang211/DataX" target="_blank" rel="noopener">DataX源码分析地址</a></p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;概述&quot;&gt;&lt;a href=&quot;#概述&quot; class=&quot;headerlink&quot; title=&quot;概述&quot;&gt;&lt;/a&gt;概述&lt;/h1&gt;&lt;p&gt;DataX 是一个异构数据源离线同步工具，致力于实现包括关系型数据库(MySQL、Oracle等)、HDFS、Hive、ODPS、HBase、FTP等各种异构数据源之间稳定高效的数据同步功能。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://github.com/alanzhang211/learning-note/raw/master/img/%E6%98%9F%E5%BD%A2%E7%8A%B6.png&quot; alt=&quot;星形状&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="大数据" scheme="http://alanzhang.me/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="2018" scheme="http://alanzhang.me/tags/2018/"/>
    
      <category term="数据同步" scheme="http://alanzhang.me/tags/%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5/"/>
    
      <category term="DataX" scheme="http://alanzhang.me/tags/DataX/"/>
    
      <category term="大数据" scheme="http://alanzhang.me/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
  </entry>
  
  <entry>
    <title>JDBC大查询内存溢出解决方案</title>
    <link href="http://alanzhang.me/2018/01/28/JDBC%E5%A4%A7%E6%9F%A5%E8%AF%A2%E5%86%85%E5%AD%98%E6%BA%A2%E5%87%BA%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/"/>
    <id>http://alanzhang.me/2018/01/28/JDBC大查询内存溢出解决方案/</id>
    <published>2018-01-28T06:53:10.000Z</published>
    <updated>2019-02-26T15:14:20.376Z</updated>
    
    <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>问题还是来源于实际项目。即席查询中，一次查询，返回大量数据会导致内存溢出问题。</p><h1 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h1><h2 id="原始方案"><a href="#原始方案" class="headerlink" title="原始方案"></a>原始方案</h2><p>直接通过jdbc链接数据库，通过遍历ResultSet获取结果。示例代码：</p><a id="more"></a><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">try &#123;</span><br><span class="line">        Class.forName(&quot;org.apache.hadoop.hive.jdbc.HiveDriver&quot;);</span><br><span class="line">        &#125; catch (ClassNotFoundException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">            System.exit(1);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        //Hive JDBC URL</span><br><span class="line">        String jdbcURL = &quot;jdbc:hive2://192.168.1.102:10000/stage&quot;;</span><br><span class="line">        Connection conn = DriverManager.getConnection(jdbcURL,&quot;test&quot;,&quot;123456&quot;);</span><br><span class="line">        Statement stmt = conn.createStatement();</span><br><span class="line">        ResultSet rs = stmt.executeQuery(sql);</span><br><span class="line">        while(rs.next()) &#123;</span><br><span class="line">            System.out.println(rs.getString(1));</span><br><span class="line">        &#125;</span><br><span class="line">        rs.close();</span><br><span class="line">        stmt.close();</span><br><span class="line">        conn.close();</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><blockquote><p>问题：这样在大查询的情况下，会导致内存溢出。</p></blockquote><h2 id="优化方案1"><a href="#优化方案1" class="headerlink" title="优化方案1"></a>优化方案1</h2><p>减少应用服务器内存压力。将查询结果存储为hdfs文件，然后通过文件流式读取数据。</p><h3 id="步骤"><a href="#步骤" class="headerlink" title="步骤"></a>步骤</h3><ol><li>导出数据到hdfs中。</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">insert overwrite [local] directory &apos;directory&apos; select_statement</span><br></pre></td></tr></table></figure><ol start="2"><li>从hdfs获取查询</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">if (fileSystem.isDirectory(fsPath)) &#123;</span><br><span class="line">        //检查hdfs文件</span><br><span class="line">        FileStatus[] status = fileSystem.globStatus(new Path(path + &quot;*&quot;));</span><br><span class="line">        for (FileStatus fileStatus : status) &#123;</span><br><span class="line">            if (fileSystem.exists(fileStatus.getPath())) &#123;</span><br><span class="line">                //写入文件(hdfs操作)</span><br><span class="line">                ...</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><blockquote><p>优点：减少应用服务器内存压力，避免了内存溢出OOM的风险。<br>缺点：需要增加hdfs登录过程（不方便对接第三方的数据源：需要处理不同安全认证登陆（ldap、kerberos等）；hdfs的多结点备份，浪费很多存储；不建议小文件存储在hdfs中。</p></blockquote><h2 id="优化方案2"><a href="#优化方案2" class="headerlink" title="优化方案2"></a>优化方案2</h2><p>使用数据库内置的流式查询。示例代码：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line">private void sendFile(Connection connection, String fileName, String sql) throws Exception &#123;</span><br><span class="line">        PreparedStatement stmt = null;</span><br><span class="line">        ResultSet rs = null;</span><br><span class="line">        FileOutputStream fos = null;</span><br><span class="line">        BufferedWriter writer = null;</span><br><span class="line">        File file = null;</span><br><span class="line">        try &#123;</span><br><span class="line">            //写入本地文件</span><br><span class="line">            file = new File(fileName);</span><br><span class="line">            fos = new FileOutputStream(file);</span><br><span class="line">            writer = new BufferedWriter(new OutputStreamWriter(fos, &quot;UTF-8&quot;),WeMetaConstant.MAX_DATA_LENGTH);</span><br><span class="line">            stmt = connection.prepareStatement(sql, ResultSet.TYPE_FORWARD_ONLY, ResultSet.CONCUR_READ_ONLY);</span><br><span class="line">            stmt.setFetchSize(Integer.MIN_VALUE);</span><br><span class="line">            rs = stmt.executeQuery();</span><br><span class="line">            //获得列集</span><br><span class="line">            ResultSetMetaData rsm = rs.getMetaData();</span><br><span class="line">            int colNum = rsm.getColumnCount();</span><br><span class="line">            while(rs.next()) &#123;</span><br><span class="line">                for (int j = 1; j &lt;= colNum; j++) &#123;</span><br><span class="line">                    writer.write(rs.getObject(j) == null ? &quot;&quot; : rs.getObject(j).toString());</span><br><span class="line">                    if (j&lt;colNum) &#123;</span><br><span class="line">                        writer.write(&quot;,&quot;);</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">                writer.write(&quot;\r\n&quot;);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; catch (Exception e) &#123;</span><br><span class="line">            logger.error(&quot;error=&#123;&#125;&quot;,e);</span><br><span class="line">            throw e;</span><br><span class="line">        &#125;  finally &#123;</span><br><span class="line">            if (writer != null) &#123;</span><br><span class="line">                try &#123;</span><br><span class="line">                    writer.flush();</span><br><span class="line">                    writer.close();</span><br><span class="line">                &#125; catch (Exception e) &#123;</span><br><span class="line">                    logger.error(&quot;关闭BufferedWriter异常！&quot;);</span><br><span class="line">                &#125;</span><br><span class="line">                if (fos != null) &#123;</span><br><span class="line">                    try &#123;</span><br><span class="line">                        fos.close();</span><br><span class="line">                    &#125; catch (Exception e) &#123;</span><br><span class="line">                        logger.error(&quot;关闭FileOutputStream异常！&quot;);</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure></p><p><strong>核心代码分析</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">stmt = connection.prepareStatement(sql, ResultSet.TYPE_FORWARD_ONLY, ResultSet.CONCUR_READ_ONLY);</span><br><span class="line">stmt.setFetchSize(Integer.MIN_VALUE);</span><br></pre></td></tr></table></figure><blockquote><p>驱动中 api中指出，只有同时开启ResultSet.TYPE_FORWARD_ONLY,ResultSet.CONCUR_READ_ONLY，Integer.MIN_VALUE 三个条件才能实现流失处理。</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">/**</span><br><span class="line"> * We only stream result sets when they are forward-only, read-only, and the</span><br><span class="line"> * fetch size has been set to Integer.MIN_VALUE</span><br><span class="line"> *</span><br><span class="line"> * @return true if this result set should be streamed row at-a-time, rather</span><br><span class="line"> * than read all at once.</span><br><span class="line"> */</span><br><span class="line">protected boolean createStreamingResultSet() &#123;</span><br><span class="line">    try &#123;</span><br><span class="line">        synchronized(checkClosed().getConnectionMutex()) &#123;</span><br><span class="line">            return ((this.resultSetType == java.sql.ResultSet.TYPE_FORWARD_ONLY)</span><br><span class="line">                 &amp;&amp; (this.resultSetConcurrency == java.sql.ResultSet.CONCUR_READ_ONLY) &amp;&amp; (this.fetchSize == Integer.MIN_VALUE));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; catch (SQLException e) &#123;</span><br><span class="line">        // we can&apos;t break the interface, having this be no-op in case of error is ok</span><br><span class="line">        return false;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>优点：减少系统复杂度（相比第一种优化，减少了与hdfs系统交互过程）；更加通用，对接其他数据库时，不需要关系上层系统的差异（如：集群认证方式等）；流式方式是每次返回一个记录到内存，所以占用内存开销比较小，并且调用后会马上可以访问数据集的数据。</p></blockquote><h1 id="结语"><a href="#结语" class="headerlink" title="结语"></a>结语</h1><p>性能问题，往往可以考虑是否可以通过流式编程来优化。</p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h1&gt;&lt;p&gt;问题还是来源于实际项目。即席查询中，一次查询，返回大量数据会导致内存溢出问题。&lt;/p&gt;
&lt;h1 id=&quot;问题&quot;&gt;&lt;a href=&quot;#问题&quot; class=&quot;headerlink&quot; title=&quot;问题&quot;&gt;&lt;/a&gt;问题&lt;/h1&gt;&lt;h2 id=&quot;原始方案&quot;&gt;&lt;a href=&quot;#原始方案&quot; class=&quot;headerlink&quot; title=&quot;原始方案&quot;&gt;&lt;/a&gt;原始方案&lt;/h2&gt;&lt;p&gt;直接通过jdbc链接数据库，通过遍历ResultSet获取结果。示例代码：&lt;/p&gt;
    
    </summary>
    
      <category term="数据库" scheme="http://alanzhang.me/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
    
      <category term="2018" scheme="http://alanzhang.me/tags/2018/"/>
    
      <category term="java" scheme="http://alanzhang.me/tags/java/"/>
    
      <category term="JDBC" scheme="http://alanzhang.me/tags/JDBC/"/>
    
  </entry>
  
  <entry>
    <title>数据库连接池实现</title>
    <link href="http://alanzhang.me/2017/12/30/%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%9E%E6%8E%A5%E6%B1%A0%E5%AE%9E%E7%8E%B0/"/>
    <id>http://alanzhang.me/2017/12/30/数据库连接池实现/</id>
    <published>2017-12-30T07:08:46.000Z</published>
    <updated>2019-02-26T15:14:20.405Z</updated>
    
    <content type="html"><![CDATA[<h1 id="需求"><a href="#需求" class="headerlink" title="需求"></a>需求</h1><ul><li>数据库连接的池化管理</li><li>支持不同数据源链接池化处理</li></ul><h1 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h1><ul><li>如何维护链接对象</li><li>如何区分不同数据源池化</li><li>如何实现资源同步问题</li></ul><a id="more"></a><h1 id="分析"><a href="#分析" class="headerlink" title="分析"></a>分析</h1><h2 id="如何维护对象"><a href="#如何维护对象" class="headerlink" title="如何维护对象"></a>如何维护对象</h2><p>使用阻塞队列实现对象存储，数据结构采用LinkedBlockingDeque（同步集合，内部线程序安全）。</p><h2 id="如何区分不同数据源池化"><a href="#如何区分不同数据源池化" class="headerlink" title="如何区分不同数据源池化"></a>如何区分不同数据源池化</h2><p>即席查询中，针对不同的数据库链接，会创建不同的的数据库链接对象（connection 是线程不安全的）。为了保证安全，可以使用ThreadLocal来维护。不同的connection要缓存，并且在空闲时可以复用。内部使用数据结构ConcurrentHashMap同步集合map来维护不同数据源链接。</p><h2 id="如何实现同步"><a href="#如何实现同步" class="headerlink" title="如何实现同步"></a>如何实现同步</h2><p>如上，使用同步集合实现共享资源（数据库链接connection）的线程安全。</p><h1 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h1><h2 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h2><p>涉及到资源的创建，释放等。最初，依据自己的方式实现。发现底层需要考虑的同步，以及淘汰策略问题。写了个雏形，感觉不满意。于是，想到apache有一个专门的对象池处理组件。common-pool2。然后，查阅了相关资料。果然满足底层需求。其中相关组件介绍，这里不展开。<a href="http://www.coc88.com/h-nd.html?id=152&amp;" target="_blank" rel="noopener">common-pool2对象池(连接池)的介绍及使用</a>，这篇文章将各组件介绍的比较详细，可参考。redis的java实现<a href="https://github.com/xetorthio/jedis" target="_blank" rel="noopener">jedis</a>底层就是借用commons-pool2实现的。</p><p>然后，使用文中介绍的GenericKeyedObjectPool，其内部就是一组k-v模型。刚好满足本文需求，实现<strong>不同数据源链接池化处理</strong>。</p><h2 id="设计"><a href="#设计" class="headerlink" title="设计"></a>设计</h2><h3 id="类图"><a href="#类图" class="headerlink" title="类图"></a>类图</h3><p><img src="https://github.com/alanzhang211/blog-image/raw/master/%EF%BC%8F2017/12/%E8%BD%AF%E4%BB%B6%E8%AE%BE%E8%AE%A1%EF%BC%8Fuml.jpg" alt="类图"></p><ul><li>ConnectionConfig：数据链接配置</li><li>ConnectionPoolConfig：数据库连接池配置</li><li>ConnectionFactory：数据库链接</li><li>ConnectionPool：数据库连接池</li><li>ConnectionProvider：数据库链接接口</li><li>ConnectionProviderImpl：数据库链接实现</li></ul><h3 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line">public class ConnectionPoolTest &#123;</span><br><span class="line">    public static final String url = &quot;jdbc:mysql://127.0.0.1/mysql&quot;;</span><br><span class="line">    public static final String driver = &quot;com.mysql.jdbc.Driver&quot;;</span><br><span class="line">    public static final String user = &quot;root&quot;;</span><br><span class="line">    public static final String password = &quot;alan&quot;;</span><br><span class="line">    public static final String sql = &quot;select 1;&quot;;</span><br><span class="line"></span><br><span class="line">    public static void testPool() throws Exception&#123;</span><br><span class="line">        ConnectionPoolConfig connectionPoolConfig = new ConnectionPoolConfig();</span><br><span class="line">        connectionPoolConfig.setMaxTotalPerKey(1);</span><br><span class="line">        connectionPoolConfig.setMaxTotal(1);</span><br><span class="line"></span><br><span class="line">        ConnectionFactory connectionFactory = new ConnectionFactory();</span><br><span class="line">        ConnectionConfig connectionConfig = new ConnectionConfig();</span><br><span class="line">        connectionConfig.setDriver(driver);</span><br><span class="line">        connectionConfig.setUser(user);</span><br><span class="line">        connectionConfig.setPassword(password);</span><br><span class="line">        connectionConfig.setUrl(url);</span><br><span class="line">        connectionFactory.create(connectionConfig);</span><br><span class="line">        ConnectionPool connectionPool = new ConnectionPool(connectionFactory,connectionPoolConfig);</span><br><span class="line">        Connection connection = connectionPool.borrowObject(connectionConfig);</span><br><span class="line">        PreparedStatement preparedStatement = connection.prepareStatement(sql);</span><br><span class="line">        ResultSet rs = preparedStatement.executeQuery();</span><br><span class="line">        System.out.println(rs.getRow());</span><br><span class="line"></span><br><span class="line">        connectionPool.returnObject(connectionConfig,connection);</span><br><span class="line"></span><br><span class="line">        Connection connection1 = connectionPool.borrowObject(connectionConfig);</span><br><span class="line">        preparedStatement = connection1.prepareStatement(&quot;select 2&quot;);</span><br><span class="line">        System.out.println(connection.equals(connection1));</span><br><span class="line">        rs = preparedStatement.executeQuery();</span><br><span class="line">        System.out.println(rs.getRow());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public static void testConnectionProvider() throws Exception &#123;</span><br><span class="line">        ConnectionPoolConfig connectionPoolConfig = new ConnectionPoolConfig();</span><br><span class="line">        connectionPoolConfig.setMaxTotalPerKey(1);</span><br><span class="line">        connectionPoolConfig.setMaxTotal(1);</span><br><span class="line"></span><br><span class="line">        ConnectionFactory connectionFactory = new ConnectionFactory();</span><br><span class="line">        ConnectionConfig connectionConfig = new ConnectionConfig();</span><br><span class="line">        connectionConfig.setDriver(driver);</span><br><span class="line">        connectionConfig.setUser(user);</span><br><span class="line">        connectionConfig.setPassword(password);</span><br><span class="line">        connectionConfig.setUrl(url);</span><br><span class="line">        connectionFactory.create(connectionConfig);</span><br><span class="line">        ConnectionPool connectionPool = new ConnectionPool(connectionFactory,connectionPoolConfig);</span><br><span class="line"></span><br><span class="line">        ConnectionProvider connectionProvider = new ConnectionProviderImpl(connectionPool);</span><br><span class="line"></span><br><span class="line">        Connection connection = connectionProvider.getConnection(connectionConfig);</span><br><span class="line">        PreparedStatement preparedStatement = connection.prepareStatement(sql);</span><br><span class="line">        ResultSet rs = preparedStatement.executeQuery();</span><br><span class="line">        System.out.println(rs.getRow());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public static void main(String[] args) throws Exception &#123;</span><br><span class="line">        ConnectionPoolTest connectionPoolTest = new ConnectionPoolTest();</span><br><span class="line">        connectionPoolTest.testConnectionProvider();</span><br><span class="line"></span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;需求&quot;&gt;&lt;a href=&quot;#需求&quot; class=&quot;headerlink&quot; title=&quot;需求&quot;&gt;&lt;/a&gt;需求&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;数据库连接的池化管理&lt;/li&gt;
&lt;li&gt;支持不同数据源链接池化处理&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&quot;问题&quot;&gt;&lt;a href=&quot;#问题&quot; class=&quot;headerlink&quot; title=&quot;问题&quot;&gt;&lt;/a&gt;问题&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;如何维护链接对象&lt;/li&gt;
&lt;li&gt;如何区分不同数据源池化&lt;/li&gt;
&lt;li&gt;如何实现资源同步问题&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
      <category term="java" scheme="http://alanzhang.me/categories/java/"/>
    
    
      <category term="2017" scheme="http://alanzhang.me/tags/2017/"/>
    
      <category term="数据库" scheme="http://alanzhang.me/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
      <category term="连接池" scheme="http://alanzhang.me/tags/%E8%BF%9E%E6%8E%A5%E6%B1%A0/"/>
    
  </entry>
  
  <entry>
    <title>香港100华东区热身派对小记</title>
    <link href="http://alanzhang.me/2017/12/18/%E9%A6%99%E6%B8%AF100%E5%8D%8E%E4%B8%9C%E5%8C%BA%E7%83%AD%E8%BA%AB%E6%B4%BE%E5%AF%B9%E5%B0%8F%E8%AE%B0/"/>
    <id>http://alanzhang.me/2017/12/18/香港100华东区热身派对小记/</id>
    <published>2017-12-18T06:46:28.000Z</published>
    <updated>2019-02-26T15:14:20.413Z</updated>
    
    <content type="html"><![CDATA[<h1 id="序"><a href="#序" class="headerlink" title="序"></a>序</h1><p>周六，参加了华东区举办的HK100赛前分享会。作为一只，初入越野圈的菜鸟来说，也是去观摩大神的。流程大体：先来个热身，20km，1200多米的爬升的热身跑。实际跑下来，接近25km。然后，洗澡午餐。下午进行赛事分享。港百介绍，路线图分析。往届参赛人员经验分享。最后，是抽奖环节。</p><p><img src="https://github.com/alanzhang211/blog-image/raw/master/%EF%BC%8F2017/12/hk100/%E5%B0%8F%E4%BA%BA.jpeg" alt="image"></p><a id="more"></a><h1 id="热身赛"><a href="#热身赛" class="headerlink" title="热身赛"></a>热身赛</h1><p><strong>线路图</strong></p><p><img src="https://github.com/alanzhang211/blog-image/raw/master/%EF%BC%8F2017/12/hk100/%E7%83%AD%E8%BA%AB%E5%9B%BE.jpeg" alt="image"></p><p>大华山，五云山。这些，都是很多赛事要经过的地方。不过，杭州群山的线路。正跑，反跑，是不一样的感觉。有些线路，走过了。突然发现，似曾相识。群山上的路线也是纵横交错。当然，这几年下来，山上的野路少了。替代的是一级级的台阶。圈内都说，杭州的越野就是爬台阶。</p><p>这次，是陪将要参加港百的小伙伴一起来的。上次因为寒流来袭，未能完赛。这次也是去收复失地。在这里，祝愿安全完赛。有些比赛，如果没能完赛，对一个参赛选手打击还是挺大的。比如我，去年的维斯越野，由于之前髂胫疼<a href="http://iranshao.com/articles/itbs_1" target="_blank" rel="noopener">髂胫束综合征</a>，导致中途退赛，很遗憾。那么，今年再次参加维斯。没有伤痛，完赛。</p><p><strong>跑步</strong><br><img src="https://github.com/alanzhang211/blog-image/raw/master/%EF%BC%8F2017/12/hk100/%E8%B7%91%E6%AD%A5.jpeg" alt="image"></p><p>跑到中途，下雨。迷路还是有的。不过，山上跑起来还是很爽，就是有点冷。跟随的都是些要参加港百的人。实力不容小觑，我这个小跟班，也就在后面学习。</p><p>经过，4个小时左右，跑回到了终点。然后，将衣服换下，洗个澡。吃上热乎乎的咖喱肌肉饭，美滋滋。</p><p><strong>冲线</strong></p><p><img src="https://github.com/alanzhang211/blog-image/raw/master/%EF%BC%8F2017/12/hk100/%E5%86%B2%E7%BA%BF.jpeg" alt="冲线"></p><p><strong>吃饭饭</strong></p><p><img src="https://github.com/alanzhang211/blog-image/raw/master/%EF%BC%8F2017/12/hk100/WechatIMG30.jpeg" alt="吃饭饭"></p><h1 id="分享"><a href="#分享" class="headerlink" title="分享"></a>分享</h1><p>大概14点的样子，组织方开始进行港百分享。分享嘉宾杰哥（方正杰，港百锦英选手）。配合地图讲解了每个cp点，道路，补给，以及注意事项。当然，风景也是很美哒。美丽的海滩，山丘，城市夜景。</p><p><strong>分享</strong></p><p><img src="https://github.com/alanzhang211/blog-image/raw/master/%EF%BC%8F2017/12/hk100/WechatIMG31.jpeg" alt="image"></p><p><strong>地图</strong></p><p><img src="https://github.com/alanzhang211/blog-image/raw/master/%EF%BC%8F2017/12/hk100/WX20171217-201436.png" alt="hk地图"></p><p><strong>爬升图</strong></p><p><img src="https://github.com/alanzhang211/blog-image/raw/master/%EF%BC%8F2017/12/hk100/elevation_profile.png" alt="image"></p><p><strong>景色</strong></p><p><img src="https://github.com/alanzhang211/blog-image/raw/master/%EF%BC%8F2017/12/hk100/%E6%B5%B7%E6%BB%A9.jpeg" alt="hk景色"></p><p><img src="https://github.com/alanzhang211/blog-image/raw/master/%EF%BC%8F2017/12/hk100/timg.jpeg" alt="image"></p><p>分享完后，就是激动的抽奖环节。这次呢？来者人人有份。帽子，压缩衣，跑步T，袜子等。</p><p><strong>奖品</strong></p><p><img src="https://github.com/alanzhang211/blog-image/raw/master/%EF%BC%8F2017/12/hk100/%E5%A5%96%E5%93%81.jpeg" alt="奖品"></p><p><strong>合影</strong></p><p><img src="https://github.com/alanzhang211/blog-image/raw/master/%EF%BC%8F2017/12/hk100/%E5%90%88%E5%BD%B1.jpeg" alt="image"></p><h1 id="时间表"><a href="#时间表" class="headerlink" title="时间表"></a>时间表</h1><p>如果打算或即将参加香港100的同学，可以参考下列时间表。分配体力，调整状态，避免跑崩。</p><p><strong>小金人</strong></p><p><img src="https://github.com/alanzhang211/blog-image/raw/master/%EF%BC%8F2017/12/hk100/%E5%B0%8F%E9%87%91%E4%BA%BA.jpg" alt="image"></p><p><strong>小银人</strong></p><p><img src="https://github.com/alanzhang211/blog-image/raw/master/%EF%BC%8F2017/12/hk100/%E5%B0%8F%E9%93%B6%E4%BA%BA.jpg" alt="image"></p><p><strong>小铜人</strong></p><p><img src="https://github.com/alanzhang211/blog-image/raw/master/%EF%BC%8F2017/12/hk100/%E5%B0%8F%E9%93%9C%E4%BA%BA.jpg" alt="image"></p><p>淡然，如果有实力跑个精英（每届只取前150名）。参考：</p><p><strong>精英</strong></p><p><img src="https://github.com/alanzhang211/blog-image/raw/master/%EF%BC%8F2017/12/hk100/%E9%87%91%E9%B9%B0.jpg" alt="image"></p><hr><p>上期推出“留言送药”活动。截止今天0点，点赞最多的读者诞生。谢谢大家的支持！</p><hr>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;序&quot;&gt;&lt;a href=&quot;#序&quot; class=&quot;headerlink&quot; title=&quot;序&quot;&gt;&lt;/a&gt;序&lt;/h1&gt;&lt;p&gt;周六，参加了华东区举办的HK100赛前分享会。作为一只，初入越野圈的菜鸟来说，也是去观摩大神的。流程大体：先来个热身，20km，1200多米的爬升的热身跑。实际跑下来，接近25km。然后，洗澡午餐。下午进行赛事分享。港百介绍，路线图分析。往届参赛人员经验分享。最后，是抽奖环节。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://github.com/alanzhang211/blog-image/raw/master/%EF%BC%8F2017/12/hk100/%E5%B0%8F%E4%BA%BA.jpeg&quot; alt=&quot;image&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="户外运动" scheme="http://alanzhang.me/categories/%E6%88%B7%E5%A4%96%E8%BF%90%E5%8A%A8/"/>
    
    
      <category term="2017" scheme="http://alanzhang.me/tags/2017/"/>
    
      <category term="户外运动" scheme="http://alanzhang.me/tags/%E6%88%B7%E5%A4%96%E8%BF%90%E5%8A%A8/"/>
    
      <category term="港百" scheme="http://alanzhang.me/tags/%E6%B8%AF%E7%99%BE/"/>
    
  </entry>
  
</feed>
